{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Arguments\n",
    "args_text = '--base-model sentence-transformers/all-MiniLM-L6-v2 '+\\\n",
    "            '--dataset news --n-word 5000 --epochs-1 200 --epochs-2 50 ' + \\\n",
    "            '--bsz 32 --stage-2-lr 2e-2 --stage-2-repeat 5 --coeff-1-dist 50 '+ \\\n",
    "            '--n-cluster 50 ' + \\\n",
    "            '--stage-1-ckpt trained_model/news_model_all-MiniLM-L6-v2_stage1_50t_5000w_199e.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import argparse\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtools.optim import RangerLars\n",
    "import gensim.downloader\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from utils import AverageMeter\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from pytorch_transformers import *\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import scipy.stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import OPTICS\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sp\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import combinations\n",
    "import gensim.downloader\n",
    "from scipy.linalg import qr\n",
    "from data import *\n",
    "from model import ContBertTopicExtractorAE\n",
    "from evaluation import get_topic_qualities\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Contrastive topic modeling')\n",
    "    parser.add_argument('--epochs-1', default=100, type=int,\n",
    "                        help='Number of training epochs for Stage 1')\n",
    "    parser.add_argument('--epochs-2', default=10, type=int,\n",
    "                        help='Number of training epochs for Stage 2')\n",
    "    parser.add_argument('--bsz', type=int, default=64,\n",
    "                        help='Batch size')\n",
    "    parser.add_argument('--dataset', default='news', type=str,\n",
    "                        choices=['news', 'twitter', 'wiki', 'nips', 'stackoverflow', 'reuters', 'r52', 'imdb'],\n",
    "                        help='Name of the dataset')\n",
    "    parser.add_argument('--n-cluster', default=20, type=int,\n",
    "                        help='Number of clusters')\n",
    "    parser.add_argument('--n-topic', type=int,\n",
    "                        help='Number of topics. If not specified, use same value as --n-cluster')\n",
    "    parser.add_argument('--n-word', default=2000, type=int,\n",
    "                        help='Number of words in vocabulary')\n",
    "    \n",
    "    parser.add_argument('--base-model', type=str,\n",
    "                        help='Name of base model in huggingface library.')\n",
    "    \n",
    "    parser.add_argument('--gpus', default=[0,1], type=int, nargs='+',\n",
    "                        help='List of GPU numbers to use. Use 0 by default')\n",
    "    \n",
    "    parser.add_argument('--coeff-1-sim', default=1.0, type=float,\n",
    "                        help='Coefficient for NN dot product similarity loss (Phase 1)')\n",
    "    parser.add_argument('--coeff-1-dist', default=1.0, type=float,\n",
    "                        help='Coefficient for NN SWD distribution loss (Phase 1)')\n",
    "    parser.add_argument('--dirichlet-alpha-1', type=float,\n",
    "                        help='Parameter for Dirichlet distribution (Phase 1). Use 1/n_topic by default.')\n",
    "    \n",
    "    parser.add_argument('--stage-1-ckpt', type=str,\n",
    "                        help='Name of torch checkpoint file Stage 1. If this argument is given, skip Stage 1.')\n",
    "    \n",
    "    parser.add_argument('--coeff-2-recon', default=1.0, type=float,\n",
    "                        help='Coefficient for VAE reconstruction loss (Phase 2)')\n",
    "    parser.add_argument('--coeff-2-regul', default=1.0, type=float,\n",
    "                        help='Coefficient for VAE KLD regularization loss (Phase 2)')\n",
    "    parser.add_argument('--coeff-2-cons', default=1.0, type=float,\n",
    "                        help='Coefficient for CL consistency loss (Phase 2)')\n",
    "    parser.add_argument('--coeff-2-dist', default=1.0, type=float,\n",
    "                        help='Coefficient for CL SWD distribution matching loss (Phase 2)')\n",
    "    parser.add_argument('--dirichlet-alpha-2', type=float,\n",
    "                        help='Parameter for Dirichlet distribution (Phase 2). Use same value as dirichlet-alpha-1 by default.')\n",
    "    \n",
    "    parser.add_argument('--stage-2-lr', default=2e-1, type=float,\n",
    "                        help='Learning rate of phase 2')\n",
    "    parser.add_argument('--stage-2-repeat', default=5, type=int,\n",
    "                        help='Repetition count of phase 2')\n",
    "    \n",
    "    parser.add_argument('--result-file', type=str,\n",
    "                        help='File name for result summary')\n",
    "    parser.add_argument('--palmetto-dir', type=str, default='./',\n",
    "                        help='Directory where palmetto JAR and the Wikipedia index are. For evaluation')\n",
    "    \n",
    "    \n",
    "    # Check if the code is run in Jupyter notebook\n",
    "    is_in_jupyter = False\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            is_in_jupyter = True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            is_in_jupyter = False  # Terminal running IPython\n",
    "        else:\n",
    "            is_in_jupyter = False  # Other type (?)\n",
    "    except NameError:\n",
    "        is_in_jupyter = False\n",
    "    \n",
    "    if is_in_jupyter:\n",
    "        return parser.parse_args(args=args_text.split())\n",
    "    else:\n",
    "        return parser.parse_args()\n",
    "\n",
    "def data_load(dataset_name):\n",
    "    should_measure_hungarian = False\n",
    "    if dataset_name == 'news':\n",
    "        textData = newsData()\n",
    "        should_measure_hungarian = True\n",
    "    elif dataset_name == 'imdb':\n",
    "        textData = IMDBData()\n",
    "    elif dataset_name == 'agnews':\n",
    "        textData = AGNewsData()\n",
    "    elif dataset_name == 'yahoo':\n",
    "        textData = YahooData()\n",
    "    elif dataset_name == 'twitter':\n",
    "        textData = twitterData('/home/data/topicmodel/twitter_covid19.tsv')\n",
    "    elif dataset_name == 'wiki':\n",
    "        textData = wikiData('/home/data/topicmodel/smplAbstracts/')\n",
    "    elif dataset_name == 'nips':\n",
    "        textData = nipsData('/home/data/topicmodel/papers.csv')\n",
    "    elif dataset_name == 'stackoverflow':\n",
    "        textData = stackoverflowData('/home/data/topicmodel/stack_overflow.csv')\n",
    "    elif dataset_name == 'reuters':\n",
    "        textData = reutersData('/home/data/topicmodel/reuters-21578.txt')\n",
    "    elif dataset_name == 'r52':\n",
    "        textData = r52Data('/home/data/topicmodel/r52/')\n",
    "        should_measure_hungarian = True\n",
    "    return textData, should_measure_hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = _parse_args()\n",
    "bsz = args.bsz\n",
    "epochs_1 = args.epochs_1\n",
    "epochs_2 = args.epochs_2\n",
    "\n",
    "n_cluster = args.n_cluster\n",
    "n_topic = args.n_topic if (args.n_topic is not None) else n_cluster\n",
    "args.n_topic = n_topic\n",
    "\n",
    "textData, should_measure_hungarian = data_load(args.dataset)\n",
    "\n",
    "ema_alpha = 0.99\n",
    "n_word = args.n_word\n",
    "if args.dirichlet_alpha_1 is None:\n",
    "    dirichlet_alpha_1 = 1 / n_cluster\n",
    "else:\n",
    "    dirichlet_alpha_1 = args.dirichlet_alpha_1\n",
    "if args.dirichlet_alpha_2 is None:\n",
    "    dirichlet_alpha_2 = dirichlet_alpha_1\n",
    "else:\n",
    "    dirichlet_alpha_2 = args.dirichlet_alpha_2\n",
    "    \n",
    "bert_name = args.base_model\n",
    "bert_name_short = bert_name.split('/')[-1]\n",
    "gpu_ids = args.gpus\n",
    "\n",
    "skip_stage_1 = (args.stage_1_ckpt is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 350/350 [00:00<00:00, 350kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 440kB/s] \n",
      "Downloading: 100%|██████████| 455k/455k [00:00<00:00, 591kB/s] \n",
      "Downloading: 100%|██████████| 112/112 [00:00<?, ?B/s] \n",
      "100%|██████████| 11314/11314 [00:09<00:00, 1233.27it/s]\n",
      "Downloading .gitattributes: 100%|██████████| 1.23k/1.23k [00:00<00:00, 410kB/s]\n",
      "Downloading 1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 95.0kB/s]\n",
      "Downloading README.md: 100%|██████████| 10.7k/10.7k [00:00<00:00, 3.55MB/s]\n",
      "Downloading config.json: 100%|██████████| 612/612 [00:00<00:00, 306kB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 58.0kB/s]\n",
      "Downloading data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 152kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 90.9M/90.9M [00:00<00:00, 112MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:02<00:00, 33.5MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 26.5kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 37.3kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 591kB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 175kB/s]\n",
      "Downloading train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 4.38MB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 440kB/s]\n",
      "Downloading modules.json: 100%|██████████| 349/349 [00:00<00:00, 175kB/s]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003000020980834961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 11314,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a1c8a05d6c46dd9f08d68cc21b336f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainds = BertDataset(bert=bert_name, text_list=textData.data, N_word=n_word, vectorizer=None, lemmatize=True)\n",
    "basesim_path = f\"./save/{args.dataset}_{bert_name_short}_basesim_matrix_full.pkl\"\n",
    "if os.path.isfile(basesim_path) == False:\n",
    "    model = SentenceTransformer(bert_name.split('/')[-1], device='cuda')\n",
    "    base_result_list = []\n",
    "    for text in tqdm_notebook(trainds.nonempty_text):\n",
    "        base_result_list.append(model.encode(text))\n",
    "        \n",
    "    base_result_embedding = np.stack(base_result_list)\n",
    "    basereduced_norm = F.normalize(torch.tensor(base_result_embedding), dim=-1)\n",
    "    basesim_matrix = torch.mm(basereduced_norm, basereduced_norm.t())\n",
    "    ind = np.diag_indices(basesim_matrix.shape[0])\n",
    "    basesim_matrix[ind[0], ind[1]] = torch.ones(basesim_matrix.shape[0]) * -1\n",
    "    torch.save(basesim_matrix, basesim_path)\n",
    "else:\n",
    "    basesim_matrix = torch.load(basesim_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Discovery neighborhood pairs and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_match_loss(hidden, alpha=1.0):\n",
    "    device = hidden.device\n",
    "    hidden_dim = hidden.shape[-1]\n",
    "    rand_w = torch.Tensor(np.eye(hidden_dim, dtype=np.float64)).to(device)\n",
    "    loss_dist_match = get_swd_loss(hidden, rand_w, alpha)\n",
    "    return loss_dist_match\n",
    "\n",
    "\n",
    "def get_swd_loss(states, rand_w, alpha=1.0):\n",
    "    device = states.device\n",
    "    states_shape = states.shape\n",
    "    states = torch.matmul(states, rand_w)\n",
    "    states_t, _ = torch.sort(states.t(), dim=1)\n",
    "\n",
    "    states_prior = torch.Tensor(np.random.dirichlet([alpha]*states_shape[1], states_shape[0])).to(device) # (bsz, dim)\n",
    "    states_prior = torch.matmul(states_prior, rand_w) # (dim, dim)\n",
    "    states_prior_t, _ = torch.sort(states_prior.t(), dim=1) # (dim, bsz)\n",
    "    return torch.mean(torch.sum((states_prior_t - states_t) ** 2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_stage_1:\n",
    "    model = ContBertTopicExtractorAE(N_topic=n_cluster, N_word=n_word, bert=bert_name, bert_dim=768)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=gpu_ids)\n",
    "    model.cuda(gpu_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = args.bsz = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not skip_stage_1:\n",
    "    losses = AverageMeter()\n",
    "    closses = AverageMeter() \n",
    "    dlosses = AverageMeter() \n",
    "    rlosses = AverageMeter() \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    temp_basesim_matrix = copy.deepcopy(basesim_matrix)\n",
    "    finetuneds = FinetuneDataset(trainds, temp_basesim_matrix, ratio=1, k=1)\n",
    "    trainloader = DataLoader(finetuneds, batch_size=bsz, shuffle=True, num_workers=0)\n",
    "    memoryloader = DataLoader(finetuneds, batch_size=bsz * 2, shuffle=False, num_workers=0)\n",
    "\n",
    "    optimizer = RangerLars(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "    global_step = 0\n",
    "    memory_queue = F.softmax(torch.randn(512, n_cluster).cuda(gpu_ids[0]), dim=1)\n",
    "    for epoch in range(epochs_1):\n",
    "        model.train()\n",
    "        #ema_model.train()\n",
    "        tbar = tqdm_notebook(trainloader)\n",
    "        for batch_idx, batch in enumerate(tbar):       \n",
    "            org_input, pos_input, _, _ = batch\n",
    "            org_input_ids = org_input['input_ids'].cuda(gpu_ids[0])\n",
    "            org_attention_mask = org_input['attention_mask'].cuda(gpu_ids[0])\n",
    "            pos_input_ids = pos_input['input_ids'].cuda(gpu_ids[0])\n",
    "            pos_attention_mask = pos_input['attention_mask'].cuda(gpu_ids[0])\n",
    "            batch_size = org_input_ids.size(0)\n",
    "\n",
    "            all_input_ids = torch.cat((org_input_ids, pos_input_ids), dim=0)\n",
    "            all_attention_masks = torch.cat((org_attention_mask, pos_attention_mask), dim=0)\n",
    "            all_topics, _ = model(all_input_ids, all_attention_masks, return_topic=True)\n",
    "\n",
    "            orig_topic, pos_topic = torch.split(all_topics, len(all_topics) // 2)\n",
    "            pos_sim = torch.sum(orig_topic * pos_topic, dim=-1)\n",
    "\n",
    "            # consistency loss\n",
    "            consistency_loss = -pos_sim.mean()\n",
    "\n",
    "            # distribution matching loss\n",
    "            memory_queue = torch.cat((memory_queue.detach(), all_topics), dim=0)[all_topics.size(0):]\n",
    "            distmatch_loss = dist_match_loss(memory_queue, dirichlet_alpha_1)\n",
    "            loss = args.coeff_1_sim * consistency_loss + \\\n",
    "                   10 * distmatch_loss\n",
    "\n",
    "            losses.update(loss.item(), bsz)\n",
    "            closses.update(consistency_loss.item(), bsz)\n",
    "            dlosses.update(distmatch_loss.item(), bsz)\n",
    "\n",
    "            tbar.set_description(\"Epoch-{} / consistency: {:.5f} - dist: {:.5f}\".format(epoch, \n",
    "                                                                                        closses.avg, \n",
    "                                                                                        dlosses.avg), refresh=True)\n",
    "            tbar.refresh()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()        \n",
    "            global_step += 1\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_stage_1:\n",
    "    model_stage1_name = f'./trained_model/{args.dataset}_model_{bert_name_short}_stage1_{args.n_topic}t_{args.n_word}w_{epoch}e.ckpt'\n",
    "    torch.save(model.module.state_dict(), model_stage1_name)\n",
    "else:\n",
    "    model_stage1_name = args.stage_1_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: extract vocab set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_embedding_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del ema_model\n",
    "except:\n",
    "    pass\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 612/612 [00:00<?, ?B/s] \n",
      "Downloading: 100%|██████████| 86.7M/86.7M [00:00<00:00, 93.5MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ContBertTopicExtractorAE(N_topic=n_cluster, N_word=n_word, bert=bert_name, bert_dim=768)\n",
    "model.cuda(gpu_ids[0])\n",
    "\n",
    "model.load_state_dict(torch.load(model_stage1_name), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004000425338745117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 45,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96cdbc4159a44be9c07836f6e0772f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_basesim_matrix = copy.deepcopy(basesim_matrix)\n",
    "finetuneds = FinetuneDataset(trainds, temp_basesim_matrix, ratio=1, k=1)\n",
    "memoryloader = DataLoader(finetuneds, batch_size=bsz * 2, shuffle=False, num_workers=0)\n",
    "result_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(tqdm_notebook(memoryloader)):        \n",
    "        org_input, _, _, _ = batch\n",
    "        org_input_ids = org_input['input_ids'].to(gpu_ids[0])\n",
    "        org_attention_mask = org_input['attention_mask'].to(gpu_ids[0])\n",
    "        topic, embed = model(org_input_ids, org_attention_mask, return_topic = True)\n",
    "        result_list.append(topic)\n",
    "result_embedding = torch.cat(result_list)\n",
    "_, result_topic = torch.max(result_embedding, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'text': trainds.preprocess_ctm(trainds.nonempty_text), \n",
    "     'cluster_label': result_topic.cpu().numpy()}\n",
    "cluster_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_per_class = cluster_df.groupby(['cluster_label'], as_index=False).agg({'text': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(token_pattern=r'\\b[a-zA-Z]{2,}\\b')\n",
    "ctfidf_vectorizer = CTFIDFVectorizer()\n",
    "count = count_vectorizer.fit_transform(docs_per_class.text)\n",
    "ctfidf = ctfidf_vectorizer.fit_transform(count, n_samples=len(cluster_df)).toarray()\n",
    "words = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transport to gensim\n",
    "(gensim_corpus, gensim_dict) = vect2gensim(count_vectorizer, count)\n",
    "vocab_list = set(gensim_dict.token2id.keys())\n",
    "stopwords = set(line.strip() for line in open('stopwords_en.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = [coherence_normalize(doc) for doc in trainds.nonempty_text]\n",
    "gensim_dict = Dictionary(normalized)\n",
    "resolution_score = (ctfidf - np.min(ctfidf, axis=1, keepdims=True)) / (np.max(ctfidf, axis=1, keepdims=True) - np.min(ctfidf, axis=1, keepdims=True))\n",
    "\n",
    "n_word = args.n_word\n",
    "# n_topic_word = n_word / len(docs_per_class.cluster_label.index)\n",
    "n_topic_word = n_word\n",
    "n_topic_word = 10\n",
    "\n",
    "topic_word_dict = {}\n",
    "for label in docs_per_class.cluster_label.index:\n",
    "    total_score = resolution_score[label]\n",
    "    score_higest = total_score.argsort()\n",
    "    score_higest = score_higest[::-1]\n",
    "    topic_word_list = [words[index] for index in score_higest]\n",
    "    \n",
    "    topic_word_list = [word for word in topic_word_list if len(word) >= 3]    \n",
    "    topic_word_list = [word for word in topic_word_list if word not in stopwords]    \n",
    "    topic_word_list = [word for word in topic_word_list if word in gensim_dict.token2id]\n",
    "    topic_word_dict[docs_per_class.cluster_label.iloc[label]] = topic_word_list[:int(n_topic_word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ['car', 'dealer', 'saturn', 'price', 'toyota', 'model', 'door', 'profit', 'sport', 'engine'],\n",
      "1: ['ticket', 'battery', 'launch', 'lib', 'rocket', 'pat', 'doug', 'flight', 'cost', 'exploration'],\n",
      "2: ['msg', 'food', 'sensitivity', 'chinese', 'superstition', 'reaction', 'circuit', 'diet', 'honda', 'taste'],\n",
      "3: ['bus', 'card', 'ram', 'simms', 'motherboard', 'mac', 'slot', 'board', 'bit', 'memory'],\n",
      "4: ['jesus', 'god', 'christian', 'christ', 'bible', 'church', 'life', 'faith', 'father', 'sin'],\n",
      "5: ['scsi', 'drive', 'ide', 'controller', 'mac', 'tape', 'device', 'bus', 'hard', 'quadra'],\n",
      "6: ['gun', 'firearm', 'handgun', 'weapon', 'criminal', 'amendment', 'control', 'crime', 'nra', 'safety'],\n",
      "7: ['israel', 'israeli', 'greek', 'arab', 'jew', 'war', 'palestinian', 'lebanese', 'turkish', 'lebanon'],\n",
      "8: ['israeli', 'israel', 'arab', 'jew', 'palestinian', 'policy', 'palestine', 'jewish', 'gaza', 'jerusalem'],\n",
      "9: ['image', 'file', 'gif', 'format', 'picture', 'photography', 'bmp', 'bitmap', 'convert', 'object'],\n",
      "10: ['max', 'batf', 'fbi', 'waco', 'compound', 'fire', 'weapon', 'koresh', 'government', 'child'],\n",
      "11: ['key', 'encryption', 'chip', 'privacy', 'clipper', 'security', 'secure', 'escrow', 'algorithm', 'anonymous'],\n",
      "12: ['diet', 'weight', 'order', 'tony', 'chuck', 'kent', 'van', 'food', 'fat', 'usa'],\n",
      "13: ['phone', 'mail', 'internet', 'address', 'email', 'server', 'number', 'list', 'call', 'mailing'],\n",
      "14: ['moon', 'orbit', 'lunar', 'space', 'spacecraft', 'billion', 'earth', 'solar', 'funding', 'planet'],\n",
      "15: ['printer', 'color', 'image', 'print', 'laser', 'printing', 'canon', 'graphic', 'scanner', 'font'],\n",
      "16: ['health', 'medical', 'disease', 'patient', 'insurance', 'pain', 'care', 'doctor', 'tax', 'infection'],\n",
      "17: ['god', 'atheist', 'belief', 'truth', 'christian', 'religion', 'atheism', 'exist', 'existence', 'argument'],\n",
      "18: ['doctor', 'gordon', 'bank', 'patient', 'physician', 'disease', 'medical', 'treatment', 'medicine', 'pittsburgh'],\n",
      "19: ['image', 'graphic', 'jpeg', 'font', 'pub', 'format', 'version', 'package', 'file', 'server'],\n",
      "20: ['mouse', 'wire', 'keyboard', 'wiring', 'ground', 'port', 'circuit', 'neutral', 'serial', 'box'],\n",
      "21: ['bike', 'motorcycle', 'helmet', 'dod', 'ride', 'honda', 'dog', 'mile', 'advice', 'buying'],\n",
      "22: ['window', 'file', 'instruction', 'memory', 'running', 'run', 'program', 'utility', 'version', 'swap'],\n",
      "23: ['video', 'color', 'vram', 'monitor', 'card', 'quadra', 'centris', 'apple', 'screen', 'bit'],\n",
      "24: ['jesus', 'christian', 'god', 'christ', 'church', 'sin', 'faith', 'catholic', 'bible', 'christianity'],\n",
      "25: ['drug', 'water', 'science', 'nuclear', 'russia', 'russian', 'senior', 'administration', 'scientific', 'theory'],\n",
      "26: ['morality', 'objective', 'moral', 'keith', 'atheist', 'schneider', 'allan', 'murder', 'livesey', 'tiff'],\n",
      "27: ['hockey', 'nhl', 'team', 'abc', 'game', 'devil', 'playoff', 'play', 'dare', 'coverage'],\n",
      "28: ['atf', 'dividian', 'ranch', 'nazi', 'trial', 'witness', 'abortion', 'burn', 'fire', 'death'],\n",
      "29: ['drive', 'disk', 'floppy', 'hard', 'bios', 'jumper', 'controller', 'slave', 'master', 'boot'],\n",
      "30: ['point', 'radius', 'plane', 'shaft', 'algorithm', 'surface', 'circle', 'piece', 'distance', 'center'],\n",
      "31: ['space', 'nasa', 'satellite', 'launch', 'mission', 'shuttle', 'entry', 'orbit', 'earth', 'station'],\n",
      "32: ['card', 'vga', 'driver', 'monitor', 'mode', 'ati', 'video', 'vesa', 'diamond', 'graphic'],\n",
      "33: ['armenian', 'gun', 'turkish', 'armenia', 'firearm', 'weapon', 'serdar', 'argic', 'genocide', 'turkey'],\n",
      "34: ['bible', 'book', 'biblical', 'koresh', 'christian', 'beast', 'church', 'god', 'language', 'hebrew'],\n",
      "35: ['amp', 'audio', 'sound', 'stereo', 'channel', 'voltage', 'speaker', 'signal', 'output', 'input'],\n",
      "36: ['car', 'driver', 'tire', 'engine', 'speed', 'brake', 'road', 'driving', 'wheel', 'mile'],\n",
      "37: ['window', 'manager', 'xterm', 'motif', 'icon', 'application', 'menu', 'event', 'key', 'display'],\n",
      "38: ['modem', 'apple', 'mac', 'duo', 'fpu', 'serial', 'powerbook', 'price', 'portable', 'port'],\n",
      "39: ['bike', 'dod', 'rider', 'riding', 'ride', 'dog', 'motorcycle', 'lock', 'appears', 'annual'],\n",
      "40: ['radar', 'detector', 'oil', 'car', 'sale', 'engine', 'power', 'music', 'radio', 'price'],\n",
      "41: ['baseball', 'phillies', 'jewish', 'team', 'game', 'player', 'fan', 'mets', 'suck', 'season'],\n",
      "42: ['homosexual', 'gay', 'islamic', 'islam', 'sex', 'muslim', 'homosexuality', 'men', 'cramer', 'sexual'],\n",
      "43: ['hit', 'game', 'player', 'pitching', 'run', 'team', 'pitcher', 'year', 'hitter', 'baseball'],\n",
      "44: ['president', 'output', 'government', 'job', 'stream', 'entry', 'clinton', 'remark', 'program', 'file'],\n",
      "45: ['widget', 'screen', 'monitor', 'window', 'display', 'application', 'resource', 'motif', 'server', 'set'],\n",
      "46: ['team', 'hockey', 'player', 'game', 'season', 'nhl', 'play', 'goal', 'period', 'league'],\n",
      "47: ['game', 'detroit', 'espn', 'win', 'wing', 'playoff', 'toronto', 'score', 'team', 'fan'],\n",
      "48: ['bmw', 'traffic', 'battery', 'tire', 'front', 'houston', 'dod', 'bike', 'speed', 'nntp'],\n",
      "49: ['clipper', 'chip', 'key', 'encryption', 'escrow', 'secret', 'crypto', 'algorithm', 'phone', 'pgp'],\n"
     ]
    }
   ],
   "source": [
    "for key in topic_word_dict:\n",
    "    print(f\"{key}: {topic_word_dict[key]},\")\n",
    "topic_words_list = list(topic_word_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17853986211773024\n"
     ]
    }
   ],
   "source": [
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "from nltk.corpus import stopwords as stop_words\n",
    "from gensim.utils import deaccent\n",
    "\n",
    "\n",
    "class WhiteSpacePreprocessing():\n",
    "    def __init__(self, documents, stopwords_language=\"english\", vocabulary_size=2000):\n",
    "        self.documents = documents\n",
    "        self.stopwords = set(stop_words.words(stopwords_language))\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "\n",
    "        warnings.simplefilter('always', DeprecationWarning)\n",
    "        warnings.warn(\"WhiteSpacePreprocessing is deprecated and will be removed in future versions.\"\n",
    "                      \"Use WhiteSpacePreprocessingStopwords.\")\n",
    "\n",
    "    def preprocess(self):\n",
    "        preprocessed_docs_tmp = self.documents\n",
    "        preprocessed_docs_tmp = [deaccent(doc.lower()) for doc in preprocessed_docs_tmp]\n",
    "        preprocessed_docs_tmp = [doc.translate(\n",
    "            str.maketrans(string.punctuation, ' ' * len(string.punctuation))) for doc in preprocessed_docs_tmp]\n",
    "        preprocessed_docs_tmp = [' '.join([w for w in doc.split() if len(w) > 0 and w not in self.stopwords])\n",
    "                                 for doc in preprocessed_docs_tmp]\n",
    "\n",
    "        vectorizer = CountVectorizer(max_features=self.vocabulary_size)\n",
    "        vectorizer.fit_transform(preprocessed_docs_tmp)\n",
    "        temp_vocabulary = set(vectorizer.get_feature_names())\n",
    "\n",
    "        preprocessed_docs_tmp = [' '.join([w for w in doc.split() if w in temp_vocabulary])\n",
    "                                 for doc in preprocessed_docs_tmp]\n",
    "\n",
    "        preprocessed_docs, unpreprocessed_docs, retained_indices = [], [], []\n",
    "        for i, doc in enumerate(preprocessed_docs_tmp):\n",
    "            if len(doc) > 0:\n",
    "                preprocessed_docs.append(doc)\n",
    "                unpreprocessed_docs.append(self.documents[i])\n",
    "                retained_indices.append(i)\n",
    "\n",
    "        vocabulary = list(set([item for doc in preprocessed_docs for item in doc.split()]))\n",
    "\n",
    "        return preprocessed_docs, unpreprocessed_docs, vocabulary, retained_indices\n",
    "    \n",
    "def _hungarian_match(flat_preds, flat_targets, num_samples, class_num):  \n",
    "    num_k = class_num\n",
    "    num_correct = np.zeros((num_k, num_k))\n",
    "  \n",
    "    for c1 in range(0, num_k):\n",
    "        for c2 in range(0, num_k):\n",
    "            votes = int(((flat_preds == c1) * (flat_targets == c2)).sum())\n",
    "            num_correct[c1, c2] = votes\n",
    "  \n",
    "    match = linear_assignment(num_samples - num_correct)\n",
    "    match = np.array(list(zip(*match)))\n",
    "    res = []\n",
    "    for out_c, gt_c in match:\n",
    "        res.append((out_c, gt_c))\n",
    "  \n",
    "    return res\n",
    "\n",
    "def get_document_topic(topic_words, preprocessed_documents_lemmatized):\n",
    "    topic_words_flatten = list(itertools.chain.from_iterable(topic_words))\n",
    "    if '' in topic_words_flatten:\n",
    "        topic_words_flatten.remove('')\n",
    "    topic_words_flatten = list(set(topic_words_flatten))\n",
    "    \n",
    "    vectorizer = CountVectorizer(vocabulary = topic_words_flatten)\n",
    "    vectorizer = vectorizer.fit(preprocessed_documents_lemmatized)\n",
    "    count_mat = vectorizer.transform(preprocessed_documents_lemmatized).toarray()\n",
    "    \n",
    "    count_mat_normalized = count_mat + 1e-4\n",
    "    count_mat_normalized = count_mat_normalized / count_mat_normalized.sum(axis=1).reshape(-1, 1)\n",
    "    \n",
    "    topic_mat = vectorizer.transform([' '.join(i) for i in topic_words]).toarray()\n",
    "    topic_mat_normalized = topic_mat + 1e-4\n",
    "    topic_mat_normalized = topic_mat_normalized / topic_mat_normalized.sum(axis=1).reshape(-1, 1)\n",
    "    \n",
    "    topic_mat_inverse = topic_mat_normalized @ topic_mat_normalized.transpose()\n",
    "    topic_mat_inverse = np.linalg.inv(topic_mat_inverse)\n",
    "    topic_mat_inverse = topic_mat_normalized.transpose() @ topic_mat_inverse\n",
    "    document_topic = count_mat_normalized @ topic_mat_inverse\n",
    "    return document_topic\n",
    "\n",
    "class TopicModelDataPreparationNoNumber(TopicModelDataPreparation):\n",
    "    def fit(self, text_for_contextual, text_for_bow, labels=None, wordlist=None):\n",
    "        \"\"\"\n",
    "        This method fits the vectorizer and gets the embeddings from the contextual model\n",
    "        :param text_for_contextual: list of unpreprocessed documents to generate the contextualized embeddings\n",
    "        :param text_for_bow: list of preprocessed documents for creating the bag-of-words\n",
    "        :param labels: list of labels associated with each document (optional).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.contextualized_model is None:\n",
    "            raise Exception(\"You should define a contextualized model if you want to create the embeddings\")\n",
    "\n",
    "        # TODO: this count vectorizer removes tokens that have len = 1, might be unexpected for the users\n",
    "        self.vectorizer = CountVectorizer(token_pattern=r'\\b[a-zA-Z]{2,}\\b', vocabulary=wordlist)\n",
    "\n",
    "        train_bow_embeddings = self.vectorizer.fit_transform(text_for_bow)\n",
    "        train_contextualized_embeddings = bert_embeddings_from_list(text_for_contextual, self.contextualized_model)\n",
    "        self.vocab = self.vectorizer.get_feature_names()\n",
    "        self.id2token = {k: v for k, v in zip(range(0, len(self.vocab)), self.vocab)}\n",
    "\n",
    "        if labels:\n",
    "            self.label_encoder = OneHotEncoder()\n",
    "            encoded_labels = self.label_encoder.fit_transform(np.array([labels]).reshape(-1, 1))\n",
    "        else:\n",
    "            encoded_labels = None\n",
    "\n",
    "        return CTMDataset(train_contextualized_embeddings, train_bow_embeddings, self.id2token, encoded_labels)\n",
    "    \n",
    "\n",
    "topic_words_list = list(topic_word_dict.values())\n",
    "qt = TopicModelDataPreparationNoNumber(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "sp = WhiteSpacePreprocessing(textData.data, stopwords_language='english')\n",
    "preprocessed_documents, unpreprocessed_corpus, vocab, retained_indices = sp.preprocess()\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "preprocessed_documents_lemmatized = [' '.join([lemmatizer.lemmatize(w) for w in doc.split()]) for doc in preprocessed_documents]\n",
    "\n",
    "document_topic = get_document_topic(topic_words_list, preprocessed_documents_lemmatized)\n",
    "train_target_filtered = textData.targets.squeeze()[retained_indices]\n",
    "flat_predict = torch.tensor(np.argmax(document_topic, axis=1))\n",
    "flat_target = torch.tensor(train_target_filtered).to(flat_predict.device)\n",
    "num_samples = flat_predict.shape[0]\n",
    "match = _hungarian_match(flat_predict, flat_target, num_samples, 20)    \n",
    "reordered_preds = torch.zeros(num_samples).to(flat_predict.device)\n",
    "for pred_i, target_i in match:\n",
    "    reordered_preds[flat_predict == pred_i] = int(target_i)\n",
    "acc = int((reordered_preds == flat_target.float()).sum()) / float(num_samples)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2043057067221093"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_mutual_info_score(reordered_preds, flat_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "[0.38297, 0.37417, 0.45394, 0.4029, 0.52711, 0.46109, 0.45418, 0.55963, 0.70803, 0.46116, 0.45936, 0.44008, 0.35423, 0.41555, 0.56226, 0.43982, 0.49678, 0.46482, 0.48524, 0.42333, 0.4014, 0.42947, 0.44147, 0.48501, 0.60479, 0.3648, 0.53699, 0.49483, 0.36144, 0.46488, 0.37283, 0.50334, 0.47903, 0.51682, 0.49874, 0.46293, 0.4598, 0.4054, 0.46753, 0.51152, 0.3641, 0.52537, 0.5616, 0.53919, 0.3365, 0.39359, 0.59823, 0.45953, 0.47088, 0.51779]\n",
      "0.4671290000000002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topic_N': 50,\n",
       " 'CV_wiki': 0.4671290000000002,\n",
       " 'sim_w2v': 0.2019678517246961,\n",
       " 'diversity': 0.75,\n",
       " 'filename': 'results/240509_233632.txt'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "results = get_topic_qualities(topic_words_list, args.palmetto_dir, reference_corpus=[doc.split() for doc in trainds.preprocess_ctm(trainds.nonempty_text)],\n",
    "                              filename=f'results/{now}.txt')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = [coherence_normalize(doc) for doc in trainds.nonempty_text]\n",
    "gensim_dict = Dictionary(normalized)\n",
    "\n",
    "n_word = args.n_word\n",
    "n_topic_word = n_word\n",
    "\n",
    "words_to_idx = {k: v for v, k in enumerate(words)}\n",
    "topic_word_dict = {}\n",
    "topic_score_dict = {}\n",
    "total_score_cat = []\n",
    "for label in docs_per_class.cluster_label.index:\n",
    "    total_score = resolution_score[label]\n",
    "    score_higest = total_score.argsort()\n",
    "    score_higest = score_higest[::-1]\n",
    "    topic_word_list = [words[index] for index in score_higest]\n",
    "    \n",
    "    total_score_cat.append(total_score)\n",
    "    topic_word_list = [word for word in topic_word_list if word not in stopwords]    \n",
    "    topic_word_list = [word for word in topic_word_list if word in gensim_dict.token2id]\n",
    "    topic_word_list = [word for word in topic_word_list if len(word) >= 3]    \n",
    "    topic_word_dict[docs_per_class.cluster_label.iloc[label]] = topic_word_list[:int(n_topic_word)]\n",
    "    topic_score_dict[docs_per_class.cluster_label.iloc[label]] = [total_score[words_to_idx[top_word]] for top_word in topic_word_list[:int(n_topic_word)]]\n",
    "total_score_cat = np.stack(total_score_cat, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3942"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_dup(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "topic_words_list = list(topic_word_dict.values())\n",
    "topic_word_set = list(itertools.chain.from_iterable(pd.DataFrame.from_dict(topic_word_dict).values))\n",
    "word_candidates = remove_dup(topic_word_set)[:n_word]\n",
    "n_word = len(word_candidates)\n",
    "n_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('our_word_candidates_10000.pkl', 'wb') as f:\n",
    "    pickle.dump(word_candidates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_candidates = {}\n",
    "for candidate in word_candidates:\n",
    "    weight_candidates[candidate] = [total_score_cat[label, words_to_idx[candidate]] for label in range(n_cluster)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_cand_to_idx = {k: v for v, k in enumerate(list(weight_candidates.keys()))}\n",
    "weight_cand_matrix = np.array(list(weight_candidates.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-formulate the bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_match_loss(hiddens, alpha=1.0):\n",
    "    device = hiddens.device\n",
    "    hidden_dim = hiddens.shape[-1]\n",
    "    H = np.random.randn(hidden_dim, hidden_dim)\n",
    "    Q, R = qr(H) \n",
    "    rand_w = torch.Tensor(Q).to(device)\n",
    "    loss_dist_match = get_swd_loss(hiddens, rand_w, alpha)\n",
    "    return loss_dist_match\n",
    "\n",
    "\n",
    "def js_div_loss(hidden1, hidden2):\n",
    "    m = 0.5 * (hidden1 + hidden2)\n",
    "    return kldiv(m.log(), hidden1) + kldiv(m.log(), hidden2)\n",
    "\n",
    "\n",
    "def get_swd_loss(states, rand_w, alpha=1.0):\n",
    "    device = states.device\n",
    "    states_shape = states.shape\n",
    "    states = torch.matmul(states, rand_w)\n",
    "    states_t, _ = torch.sort(states.t(), dim=1)\n",
    "\n",
    "    # Random vector with length from normal distribution\n",
    "    states_prior = torch.Tensor(np.random.dirichlet([alpha]*states_shape[1], states_shape[0])).to(device) # (bsz, dim)\n",
    "    states_prior = torch.matmul(states_prior, rand_w) # (dim, dim)\n",
    "    states_prior_t, _ = torch.sort(states_prior.t(), dim=1) # (dim, bsz)\n",
    "    return torch.mean(torch.sum((states_prior_t - states_t)**2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage2Dataset(Dataset):\n",
    "    def __init__(self, encoder, ds, basesim_matrix, word_candidates, k=1, lemmatize=False):\n",
    "        self.lemmatize = lemmatize\n",
    "        self.ds = ds\n",
    "        self.org_list = self.ds.org_list\n",
    "        self.nonempty_text = self.ds.nonempty_text\n",
    "        english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "        self.stopwords_list = set(english_stopwords)\n",
    "        self.vectorizer = CountVectorizer(vocabulary=word_candidates)\n",
    "        self.vectorizer.fit(self.preprocess_ctm(self.nonempty_text)) \n",
    "        self.bow_list = []\n",
    "        for sent in tqdm(self.nonempty_text):\n",
    "            self.bow_list.append(self.vectorize(sent))\n",
    "            \n",
    "        sim_weight, sim_indices = basesim_matrix.topk(k=k, dim=-1)\n",
    "        zip_iterator = zip(np.arange(len(sim_weight)), sim_indices.squeeze().data.numpy())\n",
    "        self.pos_dict = dict(zip_iterator)\n",
    "        \n",
    "        self.embedding_list = []\n",
    "        encoder_device = next(encoder.parameters()).device\n",
    "        for org_input in tqdm(self.org_list):\n",
    "            org_input_ids = org_input['input_ids'].to(encoder_device).reshape(1, -1)\n",
    "            org_attention_mask = org_input['attention_mask'].to(encoder_device).reshape(1, -1)\n",
    "            embedding = encoder(input_ids = org_input_ids, attention_mask = org_attention_mask)\n",
    "            self.embedding_list.append(embedding['pooler_output'].squeeze().detach().cpu())\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.org_list)\n",
    "        \n",
    "    def preprocess_ctm(self, documents):\n",
    "        preprocessed_docs_tmp = documents\n",
    "        preprocessed_docs_tmp = [doc.lower() for doc in preprocessed_docs_tmp]\n",
    "        preprocessed_docs_tmp = [doc.translate(\n",
    "            str.maketrans(string.punctuation, ' ' * len(string.punctuation))) for doc in preprocessed_docs_tmp]\n",
    "        preprocessed_docs_tmp = [' '.join([w for w in doc.split() if len(w) > 0 and w not in self.stopwords_list])\n",
    "                                 for doc in preprocessed_docs_tmp]\n",
    "        if self.lemmatize:\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            preprocessed_docs_tmp = [' '.join([lemmatizer.lemmatize(w) for w in doc.split()])\n",
    "                                     for doc in preprocessed_docs_tmp]\n",
    "        return preprocessed_docs_tmp\n",
    "        \n",
    "    def vectorize(self, text):\n",
    "        text = self.preprocess_ctm([text])\n",
    "        vectorized_input = self.vectorizer.transform(text)\n",
    "        vectorized_input = vectorized_input.toarray().astype(np.float64)\n",
    "#         vectorized_input = (vectorized_input != 0).astype(np.float64)\n",
    "\n",
    "        # Get word distribution from BoW\n",
    "        if vectorized_input.sum() == 0:\n",
    "            vectorized_input += 1e-8\n",
    "        vectorized_input = vectorized_input / vectorized_input.sum(axis=1, keepdims=True)\n",
    "        assert abs(vectorized_input.sum() - vectorized_input.shape[0]) < 0.01\n",
    "        \n",
    "        vectorized_label = torch.tensor(vectorized_input, dtype=torch.float)\n",
    "        return vectorized_label[0]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        pos_idx = self.pos_dict[idx]\n",
    "        return self.embedding_list[idx], self.embedding_list[pos_idx], self.bow_list[idx], self.bow_list[pos_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage2TestDataset(Dataset):\n",
    "    def __init__(self, encoder, ds, word_candidates, k=1, lemmatize=False):\n",
    "        self.lemmatize = lemmatize\n",
    "        self.ds = ds\n",
    "        self.org_list = self.ds.org_list\n",
    "        self.nonempty_text = self.ds.nonempty_text\n",
    "        english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "        self.stopwords_list = set(english_stopwords)\n",
    "        self.vectorizer = CountVectorizer(vocabulary=word_candidates)\n",
    "        self.vectorizer.fit(self.preprocess_ctm(self.nonempty_text)) \n",
    "        self.bow_list = []\n",
    "        for sent in tqdm(self.nonempty_text):\n",
    "            self.bow_list.append(self.vectorize(sent))\n",
    "        \n",
    "        self.embedding_list = []\n",
    "        encoder_device = next(encoder.parameters()).device\n",
    "        for org_input in tqdm(self.org_list):\n",
    "            org_input_ids = org_input['input_ids'].to(encoder_device).reshape(1, -1)\n",
    "            org_attention_mask = org_input['attention_mask'].to(encoder_device).reshape(1, -1)\n",
    "            embedding = encoder(input_ids = org_input_ids, attention_mask = org_attention_mask)\n",
    "            self.embedding_list.append(embedding['pooler_output'].squeeze().detach().cpu())\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.org_list)\n",
    "        \n",
    "    def preprocess_ctm(self, documents):\n",
    "        preprocessed_docs_tmp = documents\n",
    "        preprocessed_docs_tmp = [doc.lower() for doc in preprocessed_docs_tmp]\n",
    "        preprocessed_docs_tmp = [doc.translate(\n",
    "            str.maketrans(string.punctuation, ' ' * len(string.punctuation))) for doc in preprocessed_docs_tmp]\n",
    "        preprocessed_docs_tmp = [' '.join([w for w in doc.split() if len(w) > 0 and w not in self.stopwords_list])\n",
    "                                 for doc in preprocessed_docs_tmp]\n",
    "        if self.lemmatize:\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            preprocessed_docs_tmp = [' '.join([lemmatizer.lemmatize(w) for w in doc.split()])\n",
    "                                     for doc in preprocessed_docs_tmp]\n",
    "        return preprocessed_docs_tmp\n",
    "        \n",
    "    def vectorize(self, text):\n",
    "        text = self.preprocess_ctm([text])\n",
    "        vectorized_input = self.vectorizer.transform(text)\n",
    "        vectorized_input = vectorized_input.toarray().astype(np.float64)\n",
    "#         vectorized_input = (vectorized_input != 0).astype(np.float64)\n",
    "\n",
    "        # Get word distribution from BoW\n",
    "        if vectorized_input.sum() == 0:\n",
    "            vectorized_input += 1e-8\n",
    "        vectorized_input = vectorized_input / vectorized_input.sum(axis=1, keepdims=True)\n",
    "        assert abs(vectorized_input.sum() - vectorized_input.shape[0]) < 0.01\n",
    "        \n",
    "        vectorized_label = torch.tensor(vectorized_input, dtype=torch.float)\n",
    "        return vectorized_label[0]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.embedding_list[idx], self.bow_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11314/11314 [00:04<00:00, 2527.14it/s]\n",
      "100%|██████████| 11314/11314 [01:15<00:00, 149.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "finetuneds = Stage2Dataset(model.encoder, trainds, basesim_matrix, word_candidates, lemmatize=True)    \n",
    "\n",
    "kldiv = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "vocab_dict = finetuneds.vectorizer.vocabulary_\n",
    "vocab_dict_reverse = {i:v for v, i in vocab_dict.items()}\n",
    "print(n_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_hungarian_score(topic_dist, train_target):\n",
    "    dist = topic_dist\n",
    "    train_target_filtered = train_target\n",
    "    flat_predict = torch.tensor(np.argmax(dist, axis=1))\n",
    "    flat_target = torch.tensor(train_target_filtered).to(flat_predict.device)\n",
    "    num_samples = flat_predict.shape[0]\n",
    "    num_classes = dist.shape[1]\n",
    "    match = _hungarian_match(flat_predict, flat_target, num_samples, num_classes)    \n",
    "    reordered_preds = torch.zeros(num_samples).to(flat_predict.device)\n",
    "    for pred_i, target_i in match:\n",
    "        reordered_preds[flat_predict == pred_i] = int(target_i)\n",
    "    acc = int((reordered_preds == flat_target.float()).sum()) / float(num_samples)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_cands = torch.tensor(weight_cand_matrix.max(axis=1)).cuda(gpu_ids[0]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7532/7532 [00:06<00:00, 1216.02it/s]\n",
      "100%|██████████| 7532/7532 [00:02<00:00, 2638.18it/s]\n",
      "100%|██████████| 7532/7532 [00:49<00:00, 150.99it/s]\n"
     ]
    }
   ],
   "source": [
    "testds = BertDataset(bert=bert_name, text_list=textData.test_data, N_word=n_word, vectorizer=None, lemmatize=True)\n",
    "testds2 = Stage2TestDataset(model.encoder, testds, word_candidates, lemmatize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff   / regul: 1.00000 - recon: 1.00000 - c: 1.00000 - dist: 1.00000 \n",
      "Epoch-0 / recon: 2.86379 - dist: 0.08176 - cons: -0.28128\n",
      "Epoch-1 / recon: 2.75634 - dist: 0.06411 - cons: -0.32115\n",
      "Epoch-2 / recon: 2.70017 - dist: 0.05786 - cons: -0.33636\n",
      "Epoch-3 / recon: 2.66723 - dist: 0.05453 - cons: -0.34645\n",
      "Epoch-4 / recon: 2.64549 - dist: 0.05213 - cons: -0.35427\n",
      "Epoch-5 / recon: 2.63038 - dist: 0.05052 - cons: -0.35963\n",
      "Epoch-6 / recon: 2.61908 - dist: 0.04932 - cons: -0.36352\n",
      "Epoch-7 / recon: 2.61047 - dist: 0.04851 - cons: -0.36641\n",
      "Epoch-8 / recon: 2.60358 - dist: 0.04786 - cons: -0.36856\n",
      "Epoch-9 / recon: 2.59796 - dist: 0.04735 - cons: -0.37056\n",
      "Epoch-10 / recon: 2.59331 - dist: 0.04692 - cons: -0.37222\n",
      "Epoch-11 / recon: 2.58939 - dist: 0.04643 - cons: -0.37351\n",
      "Epoch-12 / recon: 2.58614 - dist: 0.04608 - cons: -0.37446\n",
      "Epoch-13 / recon: 2.58316 - dist: 0.04568 - cons: -0.37548\n",
      "Epoch-14 / recon: 2.58054 - dist: 0.04528 - cons: -0.37639\n",
      "Epoch-15 / recon: 2.57820 - dist: 0.04493 - cons: -0.37725\n",
      "Epoch-16 / recon: 2.57615 - dist: 0.04461 - cons: -0.37803\n",
      "Epoch-17 / recon: 2.57432 - dist: 0.04440 - cons: -0.37880\n",
      "Epoch-18 / recon: 2.57259 - dist: 0.04413 - cons: -0.37958\n",
      "Epoch-19 / recon: 2.57110 - dist: 0.04391 - cons: -0.38027\n",
      "Epoch-20 / recon: 2.56980 - dist: 0.04373 - cons: -0.38070\n",
      "Epoch-21 / recon: 2.56851 - dist: 0.04352 - cons: -0.38133\n",
      "Epoch-22 / recon: 2.56739 - dist: 0.04337 - cons: -0.38180\n",
      "Epoch-23 / recon: 2.56632 - dist: 0.04323 - cons: -0.38235\n",
      "Epoch-24 / recon: 2.56532 - dist: 0.04308 - cons: -0.38282\n",
      "Epoch-25 / recon: 2.56441 - dist: 0.04297 - cons: -0.38313\n",
      "Epoch-26 / recon: 2.56360 - dist: 0.04285 - cons: -0.38354\n",
      "Epoch-27 / recon: 2.56282 - dist: 0.04272 - cons: -0.38402\n",
      "Epoch-28 / recon: 2.56206 - dist: 0.04262 - cons: -0.38439\n",
      "Epoch-29 / recon: 2.56137 - dist: 0.04251 - cons: -0.38473\n",
      "Epoch-30 / recon: 2.56071 - dist: 0.04242 - cons: -0.38510\n",
      "Epoch-31 / recon: 2.56009 - dist: 0.04233 - cons: -0.38546\n",
      "Epoch-32 / recon: 2.55954 - dist: 0.04228 - cons: -0.38575\n",
      "Epoch-33 / recon: 2.55899 - dist: 0.04218 - cons: -0.38605\n",
      "Epoch-34 / recon: 2.55850 - dist: 0.04213 - cons: -0.38628\n",
      "Epoch-35 / recon: 2.55803 - dist: 0.04205 - cons: -0.38653\n",
      "Epoch-36 / recon: 2.55757 - dist: 0.04199 - cons: -0.38681\n",
      "Epoch-37 / recon: 2.55715 - dist: 0.04194 - cons: -0.38703\n",
      "Epoch-38 / recon: 2.55674 - dist: 0.04187 - cons: -0.38734\n",
      "Epoch-39 / recon: 2.55636 - dist: 0.04182 - cons: -0.38755\n",
      "Epoch-40 / recon: 2.55600 - dist: 0.04177 - cons: -0.38776\n",
      "Epoch-41 / recon: 2.55562 - dist: 0.04171 - cons: -0.38804\n",
      "Epoch-42 / recon: 2.55530 - dist: 0.04166 - cons: -0.38822\n",
      "Epoch-43 / recon: 2.55498 - dist: 0.04162 - cons: -0.38838\n",
      "Epoch-44 / recon: 2.55465 - dist: 0.04157 - cons: -0.38856\n",
      "Epoch-45 / recon: 2.55437 - dist: 0.04153 - cons: -0.38874\n",
      "Epoch-46 / recon: 2.55408 - dist: 0.04149 - cons: -0.38891\n",
      "Epoch-47 / recon: 2.55382 - dist: 0.04145 - cons: -0.38902\n",
      "Epoch-48 / recon: 2.55357 - dist: 0.04142 - cons: -0.38919\n",
      "Epoch-49 / recon: 2.55332 - dist: 0.04138 - cons: -0.38932\n",
      "------- Evaluation results -------\n",
      "topic-0 ['line', 'organization', 'subject', 'writes', 'card', 'bike', 'article', 'driver', 'video', 'god', 'vga', 'university', 'christian', 'mouse', 'posting']\n",
      "topic-1 ['line', 'bike', 'vga', 'card', 'modem', 'vram', 'video', 'mac', 'mouse', 'riding', 'motorcycle', 'simms', 'svga', 'vesa', 'apple']\n",
      "topic-2 ['line', 'bike', 'subject', 'organization', 'video', 'god', 'posting', 'christian', 'monitor', 'host', 'nntp', 'graphic', 'mouse', 'card', 'dod']\n",
      "topic-3 ['card', 'line', 'writes', 'organization', 'article', 'subject', 'driver', 'video', 'bike', 'vga', 'god', 'university', 'christian', 'work', 'mouse']\n",
      "topic-4 ['line', 'organization', 'subject', 'card', 'writes', 'article', 'bike', 'video', 'driver', 'university', 'posting', 'host', 'nntp', 'vga', 'mouse']\n",
      "topic-5 ['line', 'modem', 'mac', 'card', 'apple', 'organization', 'subject', 'bus', 'simms', 'motherboard', 'ram', 'slot', 'board', 'university', 'posting']\n",
      "topic-6 ['line', 'organization', 'subject', 'bike', 'card', 'writes', 'god', 'article', 'university', 'posting', 'nntp', 'host', 'mouse', 'christian', 'video']\n",
      "topic-7 ['line', 'subject', 'organization', 'card', 'bike', 'god', 'christian', 'mouse', 'writes', 'driver', 'university', 'monitor', 'window', 'posting', 'vga']\n",
      "topic-8 ['font', 'printer', 'file', 'image', 'subject', 'window', 'organization', 'color', 'graphic', 'gif', 'format', 'bmp', 'print', 'program', 'animation']\n",
      "topic-9 ['line', 'organization', 'writes', 'subject', 'article', 'card', 'god', 'bike', 'driver', 'university', 'video', 'christian', 'posting', 'nntp', 'vga']\n",
      "topic-10 ['line', 'subject', 'organization', 'card', 'bike', 'god', 'writes', 'christian', 'article', 'driver', 'video', 'university', 'jesus', 'mouse', 'posting']\n",
      "topic-11 ['writes', 'card', 'line', 'organization', 'article', 'subject', 'driver', 'video', 'god', 'vga', 'bike', 'university', 'christian', 'window', 'mouse']\n",
      "topic-12 ['line', 'batf', 'fbi', 'organization', 'writes', 'subject', 'waco', 'people', 'gun', 'article', 'law', 'government', 'weapon', 'fire', 'posting']\n",
      "topic-13 ['car', 'line', 'driver', 'organization', 'subject', 'article', 'writes', 'engine', 'dealer', 'saturn', 'toyota', 'speed', 'price', 'good', 'model']\n",
      "topic-14 ['max', 'line', 'writes', 'organization', 'subject', 'article', 'atf', 'people', 'death', 'posting', 'god', 'trial', 'government', 'university', 'dividian']\n",
      "topic-15 ['line', 'subject', 'organization', 'ticket', 'bmw', 'battery', 'posting', 'nntp', 'host', 'writes', 'article', 'university', 'launch', 'traffic', 'doug']\n",
      "topic-16 ['line', 'package', 'sale', 'software', 'bike', 'image', 'mail', 'shipping', 'disk', 'file', 'program', 'email', 'keyboard', 'port', 'bible']\n",
      "topic-17 ['key', 'chip', 'government', 'encryption', 'clipper', 'nsa', 'wiretap', 'clinton', 'escrow', 'crypto', 'secure', 'people', 'security', 'bit', 'tapped']\n",
      "topic-18 ['line', 'organization', 'subject', 'bike', 'god', 'card', 'posting', 'video', 'university', 'writes', 'host', 'christian', 'nntp', 'driver', 'article']\n",
      "topic-19 ['line', 'space', 'orbit', 'moon', 'nasa', 'subject', 'organization', 'spacecraft', 'satellite', 'article', 'writes', 'earth', 'billion', 'planet', 'shuttle']\n",
      "topic-20 ['line', 'subject', 'organization', 'card', 'bike', 'video', 'posting', 'university', 'driver', 'nntp', 'host', 'vga', 'mouse', 'writes', 'article']\n",
      "topic-21 ['line', 'organization', 'subject', 'writes', 'article', 'card', 'god', 'bike', 'driver', 'video', 'christian', 'university', 'posting', 'mouse', 'host']\n",
      "topic-22 ['key', 'clipper', 'chip', 'subject', 'organization', 'phone', 'encryption', 'internet', 'escrow', 'host', 'posting', 'nntp', 'mail', 'number', 'system']\n",
      "topic-23 ['line', 'window', 'card', 'bike', 'video', 'driver', 'graphic', 'subject', 'monitor', 'organization', 'software', 'mouse', 'christian', 'posting', 'sale']\n",
      "topic-24 ['line', 'card', 'subject', 'organization', 'bike', 'video', 'driver', 'vga', 'writes', 'window', 'god', 'university', 'posting', 'article', 'christian']\n",
      "topic-25 ['god', 'jesus', 'christian', 'faith', 'bible', 'people', 'belief', 'atheist', 'truth', 'church', 'life', 'christianity', 'christ', 'exist', 'scripture']\n",
      "topic-26 ['line', 'subject', 'bike', 'organization', 'card', 'video', 'posting', 'host', 'nntp', 'driver', 'university', 'mouse', 'window', 'dod', 'vga']\n",
      "topic-27 ['line', 'msg', 'food', 'subject', 'drug', 'organization', 'writes', 'article', 'air', 'nuclear', 'circuit', 'people', 'science', 'sensitivity', 'water']\n",
      "topic-28 ['israel', 'israeli', 'arab', 'jew', 'palestinian', 'turkish', 'greek', 'writes', 'policy', 'lebanese', 'people', 'article', 'peace', 'jewish', 'subject']\n",
      "topic-29 ['morality', 'objective', 'homosexual', 'writes', 'atheist', 'gay', 'moral', 'people', 'keith', 'article', 'islam', 'subject', 'islamic', 'organization', 'sex']\n",
      "topic-30 ['line', 'subject', 'organization', 'bike', 'posting', 'nntp', 'host', 'card', 'god', 'christian', 'university', 'video', 'window', 'color', 'software']\n",
      "topic-31 ['line', 'card', 'organization', 'writes', 'driver', 'subject', 'video', 'bike', 'god', 'article', 'vga', 'christian', 'university', 'jesus', 'mouse']\n",
      "topic-32 ['line', 'bike', 'window', 'sale', 'software', 'subject', 'monitor', 'card', 'organization', 'video', 'posting', 'christian', 'host', 'mouse', 'nntp']\n",
      "topic-33 ['team', 'hockey', 'nhl', 'player', 'game', 'play', 'season', 'playoff', 'goal', 'subject', 'organization', 'traded', 'captain', 'league', 'period']\n",
      "topic-34 ['line', 'subject', 'organization', 'bike', 'god', 'christian', 'posting', 'nntp', 'host', 'jesus', 'university', 'writes', 'article', 'card', 'mouse']\n",
      "topic-35 ['gun', 'armenian', 'firearm', 'people', 'turkish', 'handgun', 'armenia', 'weapon', 'argic', 'criminal', 'serdar', 'crime', 'genocide', 'soviet', 'control']\n",
      "topic-36 ['drive', 'scsi', 'disk', 'ide', 'hard', 'floppy', 'controller', 'subject', 'organization', 'mac', 'problem', 'boot', 'file', 'system', 'data']\n",
      "topic-37 ['line', 'card', 'subject', 'organization', 'writes', 'article', 'driver', 'video', 'god', 'vga', 'university', 'window', 'mouse', 'bike', 'posting']\n",
      "topic-38 ['line', 'bike', 'subject', 'window', 'software', 'organization', 'sale', 'monitor', 'posting', 'host', 'nntp', 'mail', 'color', 'graphic', 'package']\n",
      "topic-39 ['baseball', 'player', 'team', 'game', 'jewish', 'year', 'subject', 'season', 'phillies', 'pitcher', 'organization', 'article', 'writes', 'pitching', 'hit']\n",
      "topic-40 ['line', 'card', 'subject', 'organization', 'bike', 'window', 'video', 'vga', 'graphic', 'driver', 'posting', 'university', 'god', 'monitor', 'writes']\n",
      "topic-41 ['line', 'gordon', 'bank', 'doctor', 'disease', 'patient', 'article', 'organization', 'subject', 'medical', 'writes', 'chastity', 'shameful', 'pain', 'skepticism']\n",
      "topic-42 ['line', 'subject', 'organization', 'bike', 'god', 'writes', 'card', 'article', 'university', 'posting', 'driver', 'christian', 'video', 'host', 'nntp']\n",
      "topic-43 ['line', 'subject', 'organization', 'university', 'posting', 'nntp', 'host', 'point', 'article', 'algorithm', 'writes', 'valley', 'distribution', 'group', 'usa']\n",
      "topic-44 ['line', 'card', 'organization', 'subject', 'writes', 'bike', 'video', 'article', 'driver', 'vga', 'university', 'god', 'posting', 'host', 'nntp']\n",
      "topic-45 ['window', 'file', 'subject', 'organization', 'program', 'run', 'running', 'system', 'university', 'version', 'host', 'memory', 'nntp', 'posting', 'utility']\n",
      "topic-46 ['window', 'widget', 'monitor', 'manager', 'motif', 'subject', 'screen', 'organization', 'application', 'display', 'icon', 'program', 'problem', 'host', 'nntp']\n",
      "topic-47 ['game', 'subject', 'organization', 'team', 'win', 'detroit', 'playoff', 'university', 'espn', 'wing', 'writes', 'toronto', 'player', 'fan', 'year']\n",
      "topic-48 ['line', 'radar', 'detector', 'subject', 'organization', 'sale', 'amp', 'oil', 'power', 'audio', 'channel', 'university', 'host', 'nntp', 'car']\n",
      "topic-49 ['line', 'card', 'organization', 'subject', 'driver', 'writes', 'video', 'vga', 'god', 'article', 'bike', 'university', 'christian', 'monitor', 'posting']\n",
      "./\n",
      "[0.3612, 0.54874, 0.38406, 0.33599, 0.3899, 0.40603, 0.34445, 0.37452, 0.36393, 0.40967, 0.3068, 0.34049, 0.35183, 0.31108, 0.27191, 0.36148, 0.34545, 0.39632, 0.34725, 0.42018, 0.3899, 0.28766, 0.38719, 0.33013, 0.36254, 0.47228, 0.43453, 0.28578, 0.40643, 0.31594, 0.37419, 0.35466, 0.36276, 0.49608, 0.35846, 0.44793, 0.4138, 0.36024, 0.38087, 0.42672, 0.37198, 0.32283, 0.34725, 0.33063, 0.39186, 0.42488, 0.35729, 0.3424, 0.36388, 0.35632]\n",
      "0.37257380000000007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:00, 383.62it/s]\n",
      "59it [00:00, 536.36it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 408.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic_N': 50, 'CV_wiki': 0.37257380000000007, 'sim_w2v': 0.11059587169815185, 'diversity': 0.31066666666666665, 'filename': 'results/240509_235251.txt', 'acc': 0.07448220924057355, 'macro-F1': 0.0638077114371968, 'Purity': 0.49880509824747743, 'NMI': 0.4707201633301822, 'label_match': 0.4344175357963585}\n",
      "\n",
      "Coeff   / regul: 1.00000 - recon: 1.00000 - c: 1.00000 - dist: 1.00000 \n",
      "Epoch-0 / recon: 2.86838 - dist: 0.10385 - cons: -0.24990\n",
      "Epoch-1 / recon: 2.76356 - dist: 0.08239 - cons: -0.28325\n",
      "Epoch-2 / recon: 2.70622 - dist: 0.07164 - cons: -0.30221\n",
      "Epoch-3 / recon: 2.67133 - dist: 0.06538 - cons: -0.31726\n",
      "Epoch-4 / recon: 2.64843 - dist: 0.06142 - cons: -0.32773\n",
      "Epoch-5 / recon: 2.63246 - dist: 0.05876 - cons: -0.33427\n",
      "Epoch-6 / recon: 2.62044 - dist: 0.05669 - cons: -0.33964\n",
      "Epoch-7 / recon: 2.61118 - dist: 0.05496 - cons: -0.34379\n",
      "Epoch-8 / recon: 2.60384 - dist: 0.05372 - cons: -0.34672\n",
      "Epoch-9 / recon: 2.59788 - dist: 0.05267 - cons: -0.34953\n",
      "Epoch-10 / recon: 2.59298 - dist: 0.05187 - cons: -0.35167\n",
      "Epoch-11 / recon: 2.58865 - dist: 0.05117 - cons: -0.35379\n",
      "Epoch-12 / recon: 2.58509 - dist: 0.05057 - cons: -0.35520\n",
      "Epoch-13 / recon: 2.58194 - dist: 0.05005 - cons: -0.35696\n",
      "Epoch-14 / recon: 2.57927 - dist: 0.04959 - cons: -0.35808\n",
      "Epoch-15 / recon: 2.57685 - dist: 0.04918 - cons: -0.35922\n",
      "Epoch-16 / recon: 2.57466 - dist: 0.04885 - cons: -0.36001\n",
      "Epoch-17 / recon: 2.57261 - dist: 0.04850 - cons: -0.36081\n",
      "Epoch-18 / recon: 2.57069 - dist: 0.04815 - cons: -0.36155\n",
      "Epoch-19 / recon: 2.56899 - dist: 0.04788 - cons: -0.36230\n",
      "Epoch-20 / recon: 2.56743 - dist: 0.04754 - cons: -0.36319\n",
      "Epoch-21 / recon: 2.56599 - dist: 0.04723 - cons: -0.36410\n",
      "Epoch-22 / recon: 2.56470 - dist: 0.04695 - cons: -0.36485\n",
      "Epoch-23 / recon: 2.56348 - dist: 0.04671 - cons: -0.36558\n",
      "Epoch-24 / recon: 2.56241 - dist: 0.04646 - cons: -0.36629\n",
      "Epoch-25 / recon: 2.56138 - dist: 0.04619 - cons: -0.36713\n",
      "Epoch-26 / recon: 2.56036 - dist: 0.04597 - cons: -0.36783\n",
      "Epoch-27 / recon: 2.55939 - dist: 0.04567 - cons: -0.36866\n",
      "Epoch-28 / recon: 2.55843 - dist: 0.04537 - cons: -0.36955\n",
      "Epoch-29 / recon: 2.55755 - dist: 0.04503 - cons: -0.37046\n",
      "Epoch-30 / recon: 2.55671 - dist: 0.04470 - cons: -0.37144\n",
      "Epoch-31 / recon: 2.55593 - dist: 0.04441 - cons: -0.37246\n",
      "Epoch-32 / recon: 2.55513 - dist: 0.04413 - cons: -0.37348\n",
      "Epoch-33 / recon: 2.55434 - dist: 0.04385 - cons: -0.37443\n",
      "Epoch-34 / recon: 2.55355 - dist: 0.04356 - cons: -0.37542\n",
      "Epoch-35 / recon: 2.55283 - dist: 0.04327 - cons: -0.37643\n",
      "Epoch-36 / recon: 2.55209 - dist: 0.04299 - cons: -0.37748\n",
      "Epoch-37 / recon: 2.55140 - dist: 0.04273 - cons: -0.37843\n",
      "Epoch-38 / recon: 2.55073 - dist: 0.04246 - cons: -0.37948\n",
      "Epoch-39 / recon: 2.55010 - dist: 0.04220 - cons: -0.38044\n",
      "Epoch-40 / recon: 2.54946 - dist: 0.04197 - cons: -0.38138\n",
      "Epoch-41 / recon: 2.54886 - dist: 0.04176 - cons: -0.38233\n",
      "Epoch-42 / recon: 2.54832 - dist: 0.04154 - cons: -0.38312\n",
      "Epoch-43 / recon: 2.54780 - dist: 0.04134 - cons: -0.38389\n",
      "Epoch-44 / recon: 2.54727 - dist: 0.04114 - cons: -0.38460\n",
      "Epoch-45 / recon: 2.54676 - dist: 0.04094 - cons: -0.38533\n",
      "Epoch-46 / recon: 2.54627 - dist: 0.04075 - cons: -0.38602\n",
      "Epoch-47 / recon: 2.54579 - dist: 0.04057 - cons: -0.38676\n",
      "Epoch-48 / recon: 2.54530 - dist: 0.04041 - cons: -0.38740\n",
      "Epoch-49 / recon: 2.54486 - dist: 0.04025 - cons: -0.38798\n",
      "------- Evaluation results -------\n",
      "topic-0 ['key', 'chip', 'clipper', 'encryption', 'escrow', 'crypto', 'government', 'algorithm', 'secret', 'system', 'bit', 'organization', 'subject', 'security', 'secure']\n",
      "topic-1 ['organization', 'subject', 'line', 'sale', 'university', 'posting', 'host', 'nntp', 'distribution', 'offer', 'good', 'price', 'interested', 'graphic', 'computer']\n",
      "topic-2 ['mac', 'modem', 'card', 'apple', 'bus', 'simms', 'subject', 'organization', 'motherboard', 'ram', 'slot', 'board', 'university', 'isa', 'controller']\n",
      "topic-3 ['god', 'line', 'bible', 'christian', 'atheist', 'israeli', 'car', 'religion', 'jesus', 'israel', 'jew', 'belief', 'christianity', 'church', 'christ']\n",
      "topic-4 ['card', 'video', 'driver', 'vga', 'monitor', 'subject', 'organization', 'window', 'color', 'graphic', 'mode', 'vram', 'university', 'ati', 'svga']\n",
      "topic-5 ['god', 'line', 'bible', 'christian', 'jesus', 'atheist', 'religion', 'church', 'car', 'christ', 'belief', 'christianity', 'sale', 'faith', 'religious']\n",
      "topic-6 ['line', 'morality', 'objective', 'god', 'homosexual', 'jesus', 'jew', 'israeli', 'christian', 'gay', 'islam', 'people', 'moral', 'israel', 'atheist']\n",
      "topic-7 ['line', 'graphic', 'software', 'package', 'image', 'organization', 'animation', 'subject', 'program', 'window', 'color', 'computer', 'university', 'posting', 'host']\n",
      "topic-8 ['line', 'sale', 'car', 'subject', 'organization', 'university', 'posting', 'offer', 'nntp', 'host', 'distribution', 'price', 'shipping', 'condition', 'good']\n",
      "topic-9 ['gun', 'armenian', 'firearm', 'turkish', 'people', 'handgun', 'weapon', 'armenia', 'argic', 'criminal', 'serdar', 'crime', 'genocide', 'amendment', 'control']\n",
      "topic-10 ['window', 'screen', 'line', 'widget', 'file', 'motif', 'display', 'font', 'manager', 'monitor', 'application', 'xlib', 'program', 'server', 'color']\n",
      "topic-11 ['organization', 'subject', 'line', 'posting', 'university', 'host', 'nntp', 'sale', 'distribution', 'reply', 'offer', 'usa', 'mail', 'system', 'good']\n",
      "topic-12 ['line', 'mouse', 'subject', 'organization', 'keyboard', 'port', 'amp', 'audio', 'channel', 'university', 'serial', 'sound', 'ground', 'input', 'host']\n",
      "topic-13 ['line', 'space', 'orbit', 'moon', 'subject', 'organization', 'nasa', 'spacecraft', 'writes', 'article', 'earth', 'billion', 'satellite', 'year', 'station']\n",
      "topic-14 ['window', 'line', 'file', 'program', 'screen', 'display', 'application', 'widget', 'motif', 'server', 'graphic', 'run', 'client', 'color', 'manager']\n",
      "topic-15 ['baseball', 'team', 'game', 'player', 'year', 'jewish', 'subject', 'organization', 'article', 'writes', 'season', 'phillies', 'pitcher', 'run', 'pitching']\n",
      "topic-16 ['line', 'window', 'subject', 'graphic', 'organization', 'posting', 'sale', 'host', 'file', 'program', 'nntp', 'package', 'software', 'university', 'image']\n",
      "topic-17 ['line', 'god', 'christian', 'jesus', 'bible', 'subject', 'organization', 'church', 'christ', 'writes', 'sin', 'book', 'article', 'university', 'people']\n",
      "topic-18 ['line', 'subject', 'organization', 'posting', 'nntp', 'host', 'sale', 'university', 'distribution', 'software', 'mail', 'graphic', 'computer', 'reply', 'system']\n",
      "topic-19 ['max', 'line', 'fbi', 'batf', 'writes', 'atf', 'subject', 'organization', 'fire', 'people', 'waco', 'article', 'government', 'trial', 'law']\n",
      "topic-20 ['line', 'graphic', 'organization', 'subject', 'posting', 'host', 'nntp', 'university', 'package', 'program', 'image', 'animation', 'distribution', 'reply', 'mail']\n",
      "topic-21 ['line', 'god', 'car', 'israeli', 'israel', 'sale', 'jew', 'arab', 'monitor', 'christian', 'atheist', 'tapped', 'window', 'bible', 'religion']\n",
      "topic-22 ['line', 'subject', 'organization', 'university', 'article', 'point', 'posting', 'nntp', 'host', 'writes', 'valley', 'algorithm', 'distribution', 'usa', 'group']\n",
      "topic-23 ['line', 'monitor', 'widget', 'window', 'screen', 'subject', 'organization', 'problem', 'motif', 'host', 'nntp', 'posting', 'display', 'university', 'system']\n",
      "topic-24 ['organization', 'subject', 'host', 'posting', 'nntp', 'university', 'graphic', 'distribution', 'line', 'reply', 'mail', 'system', 'world', 'group', 'program']\n",
      "topic-25 ['line', 'morality', 'writes', 'objective', 'homosexual', 'subject', 'article', 'people', 'organization', 'gay', 'atheist', 'keith', 'moral', 'islamic', 'men']\n",
      "topic-26 ['window', 'line', 'file', 'screen', 'program', 'widget', 'motif', 'display', 'israeli', 'application', 'server', 'ftp', 'israel', 'manager', 'package']\n",
      "topic-27 ['drive', 'scsi', 'disk', 'ide', 'hard', 'floppy', 'controller', 'subject', 'organization', 'mac', 'problem', 'boot', 'file', 'system', 'device']\n",
      "topic-28 ['line', 'car', 'god', 'sale', 'bible', 'atheist', 'christian', 'jesus', 'church', 'religion', 'subject', 'shipping', 'belief', 'christ', 'organization']\n",
      "topic-29 ['line', 'car', 'detector', 'radar', 'writes', 'article', 'subject', 'organization', 'engine', 'oil', 'dealer', 'speed', 'driver', 'saturn', 'price']\n",
      "topic-30 ['line', 'msg', 'food', 'subject', 'organization', 'writes', 'article', 'drug', 'university', 'posting', 'circuit', 'people', 'host', 'air', 'nntp']\n",
      "topic-31 ['subject', 'organization', 'line', 'university', 'posting', 'sale', 'host', 'nntp', 'distribution', 'offer', 'mail', 'graphic', 'good', 'computer', 'interested']\n",
      "topic-32 ['window', 'line', 'program', 'graphic', 'file', 'organization', 'subject', 'package', 'format', 'host', 'nntp', 'posting', 'animation', 'image', 'code']\n",
      "topic-33 ['subject', 'organization', 'line', 'posting', 'host', 'nntp', 'university', 'mail', 'distribution', 'reply', 'email', 'internet', 'program', 'graphic', 'code']\n",
      "topic-34 ['god', 'line', 'jesus', 'christian', 'people', 'church', 'christ', 'bible', 'thing', 'life', 'subject', 'writes', 'faith', 'organization', 'time']\n",
      "topic-35 ['window', 'line', 'file', 'subject', 'organization', 'manager', 'program', 'host', 'icon', 'application', 'posting', 'running', 'nntp', 'university', 'problem']\n",
      "topic-36 ['line', 'subject', 'organization', 'nntp', 'posting', 'host', 'mail', 'internet', 'phone', 'file', 'number', 'address', 'ftp', 'university', 'csutexasedu']\n",
      "topic-37 ['god', 'line', 'people', 'christian', 'truth', 'atheist', 'belief', 'writes', 'article', 'faith', 'evidence', 'subject', 'question', 'arrogance', 'exist']\n",
      "topic-38 ['team', 'hockey', 'nhl', 'player', 'game', 'play', 'season', 'goal', 'subject', 'organization', 'playoff', 'period', 'writes', 'traded', 'captain']\n",
      "topic-39 ['printer', 'font', 'subject', 'organization', 'file', 'window', 'image', 'color', 'gif', 'university', 'print', 'posting', 'nntp', 'host', 'format']\n",
      "topic-40 ['line', 'subject', 'organization', 'ticket', 'bmw', 'article', 'posting', 'writes', 'nntp', 'battery', 'host', 'university', 'distribution', 'launch', 'traffic']\n",
      "topic-41 ['window', 'screen', 'line', 'file', 'widget', 'display', 'monitor', 'motif', 'color', 'application', 'program', 'font', 'graphic', 'image', 'manager']\n",
      "topic-42 ['gordon', 'bank', 'doctor', 'patient', 'disease', 'article', 'subject', 'organization', 'writes', 'medical', 'shameful', 'chastity', 'skepticism', 'intellect', 'pittsburgh']\n",
      "topic-43 ['bike', 'dod', 'motorcycle', 'article', 'writes', 'dog', 'organization', 'subject', 'riding', 'ride', 'rider', 'helmet', 'posting', 'host', 'nntp']\n",
      "topic-44 ['line', 'government', 'key', 'clinton', 'writes', 'good', 'people', 'tapped', 'nsa', 'clipper', 'system', 'subject', 'article', 'encryption', 'organization']\n",
      "topic-45 ['line', 'window', 'graphic', 'program', 'software', 'subject', 'file', 'package', 'organization', 'color', 'car', 'animation', 'sale', 'image', 'disk']\n",
      "topic-46 ['line', 'window', 'graphic', 'color', 'image', 'screen', 'file', 'package', 'display', 'program', 'car', 'software', 'animation', 'monitor', 'disk']\n",
      "topic-47 ['line', 'graphic', 'subject', 'organization', 'posting', 'nntp', 'host', 'university', 'package', 'sale', 'distribution', 'car', 'image', 'software', 'offer']\n",
      "topic-48 ['game', 'subject', 'organization', 'playoff', 'team', 'win', 'detroit', 'university', 'wing', 'toronto', 'espn', 'cup', 'player', 'writes', 'play']\n",
      "topic-49 ['israel', 'line', 'israeli', 'arab', 'jew', 'writes', 'article', 'people', 'palestinian', 'subject', 'organization', 'greek', 'turkish', 'policy', 'jewish']\n",
      "./\n",
      "[0.37336, 0.40934, 0.38838, 0.46409, 0.46628, 0.49544, 0.35651, 0.35378, 0.35341, 0.44552, 0.38408, 0.33633, 0.29335, 0.36953, 0.33789, 0.41796, 0.37571, 0.35349, 0.35492, 0.36591, 0.36783, 0.34867, 0.33063, 0.3606, 0.32757, 0.29518, 0.38128, 0.41788, 0.44763, 0.29544, 0.34194, 0.40353, 0.37153, 0.35129, 0.35899, 0.42698, 0.34122, 0.31378, 0.44829, 0.40465, 0.34771, 0.32792, 0.34862, 0.48323, 0.26397, 0.31769, 0.33462, 0.36748, 0.38131, 0.37886]\n",
      "0.37163199999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:00, 357.43it/s]\n",
      "59it [00:00, 536.36it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 412.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic_N': 50, 'CV_wiki': 0.37163199999999996, 'sim_w2v': 0.12865569502834454, 'diversity': 0.32666666666666666, 'filename': 'results/240509_235541.txt', 'acc': 0.07859798194370685, 'macro-F1': 0.057332348401032615, 'Purity': 0.5102230483271375, 'NMI': 0.4838984176956681, 'label_match': 0.43980908608803254}\n",
      "\n",
      "Coeff   / regul: 1.00000 - recon: 1.00000 - c: 1.00000 - dist: 1.00000 \n",
      "Epoch-0 / recon: 2.86445 - dist: 0.07908 - cons: -0.29007\n",
      "Epoch-1 / recon: 2.75859 - dist: 0.06574 - cons: -0.32267\n",
      "Epoch-2 / recon: 2.70197 - dist: 0.06057 - cons: -0.33736\n",
      "Epoch-3 / recon: 2.66868 - dist: 0.05741 - cons: -0.34523\n",
      "Epoch-4 / recon: 2.64704 - dist: 0.05537 - cons: -0.35014\n",
      "Epoch-5 / recon: 2.63193 - dist: 0.05404 - cons: -0.35343\n",
      "Epoch-6 / recon: 2.62052 - dist: 0.05290 - cons: -0.35606\n",
      "Epoch-7 / recon: 2.61158 - dist: 0.05212 - cons: -0.35827\n",
      "Epoch-8 / recon: 2.60460 - dist: 0.05148 - cons: -0.35965\n",
      "Epoch-9 / recon: 2.59885 - dist: 0.05108 - cons: -0.36048\n",
      "Epoch-10 / recon: 2.59400 - dist: 0.05063 - cons: -0.36164\n",
      "Epoch-11 / recon: 2.58967 - dist: 0.05013 - cons: -0.36282\n",
      "Epoch-12 / recon: 2.58589 - dist: 0.04965 - cons: -0.36421\n",
      "Epoch-13 / recon: 2.58254 - dist: 0.04922 - cons: -0.36515\n",
      "Epoch-14 / recon: 2.57951 - dist: 0.04880 - cons: -0.36631\n",
      "Epoch-15 / recon: 2.57688 - dist: 0.04854 - cons: -0.36724\n",
      "Epoch-16 / recon: 2.57451 - dist: 0.04822 - cons: -0.36803\n",
      "Epoch-17 / recon: 2.57217 - dist: 0.04768 - cons: -0.36928\n",
      "Epoch-18 / recon: 2.57004 - dist: 0.04715 - cons: -0.37064\n",
      "Epoch-19 / recon: 2.56808 - dist: 0.04663 - cons: -0.37194\n",
      "Epoch-20 / recon: 2.56623 - dist: 0.04609 - cons: -0.37350\n",
      "Epoch-21 / recon: 2.56451 - dist: 0.04560 - cons: -0.37486\n",
      "Epoch-22 / recon: 2.56288 - dist: 0.04512 - cons: -0.37632\n",
      "Epoch-23 / recon: 2.56135 - dist: 0.04470 - cons: -0.37755\n",
      "Epoch-24 / recon: 2.55993 - dist: 0.04433 - cons: -0.37866\n",
      "Epoch-25 / recon: 2.55857 - dist: 0.04395 - cons: -0.37980\n",
      "Epoch-26 / recon: 2.55726 - dist: 0.04362 - cons: -0.38068\n",
      "Epoch-27 / recon: 2.55604 - dist: 0.04327 - cons: -0.38163\n",
      "Epoch-28 / recon: 2.55490 - dist: 0.04293 - cons: -0.38253\n",
      "Epoch-29 / recon: 2.55383 - dist: 0.04262 - cons: -0.38347\n",
      "Epoch-30 / recon: 2.55282 - dist: 0.04235 - cons: -0.38427\n",
      "Epoch-31 / recon: 2.55185 - dist: 0.04205 - cons: -0.38510\n",
      "Epoch-32 / recon: 2.55095 - dist: 0.04177 - cons: -0.38585\n",
      "Epoch-33 / recon: 2.55008 - dist: 0.04152 - cons: -0.38658\n",
      "Epoch-34 / recon: 2.54926 - dist: 0.04129 - cons: -0.38727\n",
      "Epoch-35 / recon: 2.54848 - dist: 0.04107 - cons: -0.38793\n",
      "Epoch-36 / recon: 2.54775 - dist: 0.04087 - cons: -0.38844\n",
      "Epoch-37 / recon: 2.54703 - dist: 0.04067 - cons: -0.38908\n",
      "Epoch-38 / recon: 2.54635 - dist: 0.04050 - cons: -0.38960\n",
      "Epoch-39 / recon: 2.54571 - dist: 0.04032 - cons: -0.39008\n",
      "Epoch-40 / recon: 2.54506 - dist: 0.04016 - cons: -0.39051\n",
      "Epoch-41 / recon: 2.54446 - dist: 0.04001 - cons: -0.39099\n",
      "Epoch-42 / recon: 2.54389 - dist: 0.03985 - cons: -0.39142\n",
      "Epoch-43 / recon: 2.54333 - dist: 0.03971 - cons: -0.39190\n",
      "Epoch-44 / recon: 2.54278 - dist: 0.03956 - cons: -0.39228\n",
      "Epoch-45 / recon: 2.54226 - dist: 0.03943 - cons: -0.39264\n",
      "Epoch-46 / recon: 2.54177 - dist: 0.03931 - cons: -0.39302\n",
      "Epoch-47 / recon: 2.54129 - dist: 0.03918 - cons: -0.39338\n",
      "Epoch-48 / recon: 2.54081 - dist: 0.03906 - cons: -0.39375\n",
      "Epoch-49 / recon: 2.54035 - dist: 0.03895 - cons: -0.39406\n",
      "------- Evaluation results -------\n",
      "topic-0 ['team', 'game', 'line', 'hockey', 'fan', 'playoff', 'player', 'year', 'season', 'cup', 'writes', 'subject', 'play', 'organization', 'article']\n",
      "topic-1 ['article', 'line', 'organization', 'subject', 'writes', 'bank', 'computer', 'gordon', 'people', 'problem', 'doctor', 'reply', 'case', 'medical', 'work']\n",
      "topic-2 ['line', 'team', 'hockey', 'nhl', 'player', 'game', 'play', 'subject', 'organization', 'season', 'goal', 'playoff', 'writes', 'period', 'traded']\n",
      "topic-3 ['line', 'game', 'organization', 'subject', 'university', 'win', 'team', 'detroit', 'writes', 'posting', 'host', 'espn', 'nntp', 'wing', 'article']\n",
      "topic-4 ['space', 'line', 'orbit', 'moon', 'subject', 'nasa', 'organization', 'spacecraft', 'article', 'writes', 'billion', 'earth', 'satellite', 'lunar', 'year']\n",
      "topic-5 ['line', 'subject', 'organization', 'host', 'posting', 'nntp', 'mail', 'internet', 'phone', 'file', 'number', 'address', 'university', 'ftp', 'email']\n",
      "topic-6 ['line', 'subject', 'organization', 'university', 'point', 'posting', 'nntp', 'host', 'article', 'valley', 'algorithm', 'writes', 'distribution', 'usa', 'chuck']\n",
      "topic-7 ['team', 'game', 'hockey', 'playoff', 'season', 'player', 'cup', 'fan', 'nhl', 'stanley', 'league', 'win', 'toronto', 'devil', 'play']\n",
      "topic-8 ['max', 'line', 'fbi', 'batf', 'writes', 'atf', 'fire', 'organization', 'subject', 'article', 'waco', 'people', 'trial', 'government', 'death']\n",
      "topic-9 ['window', 'printer', 'line', 'graphic', 'software', 'screen', 'file', 'monitor', 'package', 'application', 'government', 'machine', 'code', 'widget', 'display']\n",
      "topic-10 ['baseball', 'player', 'team', 'game', 'jewish', 'year', 'subject', 'organization', 'season', 'pitcher', 'phillies', 'article', 'hit', 'run', 'pitching']\n",
      "topic-11 ['line', 'organization', 'subject', 'article', 'bank', 'writes', 'gordon', 'doctor', 'disease', 'medical', 'people', 'reply', 'patient', 'posting', 'time']\n",
      "topic-12 ['key', 'chip', 'clipper', 'encryption', 'escrow', 'crypto', 'government', 'algorithm', 'nsa', 'secret', 'secure', 'system', 'bit', 'security', 'phone']\n",
      "topic-13 ['god', 'christian', 'jesus', 'bible', 'church', 'christ', 'subject', 'organization', 'sin', 'writes', 'book', 'roman', 'christianity', 'article', 'university']\n",
      "topic-14 ['line', 'organization', 'subject', 'article', 'writes', 'bank', 'gordon', 'doctor', 'posting', 'year', 'host', 'nntp', 'patient', 'pittsburgh', 'people']\n",
      "topic-15 ['line', 'window', 'printer', 'software', 'government', 'file', 'code', 'screen', 'monitor', 'machine', 'graphic', 'tapped', 'application', 'honda', 'motif']\n",
      "topic-16 ['line', 'team', 'game', 'patient', 'disease', 'doctor', 'gordon', 'hockey', 'year', 'bank', 'writes', 'article', 'fan', 'subject', 'player']\n",
      "topic-17 ['article', 'organization', 'line', 'subject', 'writes', 'bank', 'gordon', 'people', 'computer', 'reply', 'problem', 'science', 'medical', 'case', 'doctor']\n",
      "topic-18 ['team', 'game', 'hockey', 'playoff', 'season', 'cup', 'fan', 'player', 'stanley', 'nhl', 'win', 'toronto', 'league', 'play', 'devil']\n",
      "topic-19 ['line', 'monitor', 'widget', 'screen', 'window', 'subject', 'organization', 'motif', 'display', 'problem', 'host', 'nntp', 'posting', 'university', 'color']\n",
      "topic-20 ['line', 'msg', 'food', 'drug', 'article', 'subject', 'writes', 'organization', 'air', 'nuclear', 'people', 'water', 'sensitivity', 'circuit', 'science']\n",
      "topic-21 ['printer', 'printing', 'canon', 'font', 'print', 'line', 'scanner', 'laser', 'image', 'dot', 'postscript', 'gif', 'widget', 'enterpoopmitedu', 'screen']\n",
      "topic-22 ['article', 'writes', 'organization', 'line', 'subject', 'bank', 'gordon', 'people', 'science', 'doctor', 'reply', 'medical', 'computer', 'case', 'problem']\n",
      "topic-23 ['line', 'article', 'subject', 'organization', 'writes', 'bank', 'gordon', 'doctor', 'reply', 'posting', 'host', 'nntp', 'medical', 'science', 'university']\n",
      "topic-24 ['morality', 'objective', 'homosexual', 'writes', 'moral', 'atheist', 'gay', 'keith', 'article', 'subject', 'people', 'islamic', 'islam', 'organization', 'sex']\n",
      "topic-25 ['window', 'file', 'manager', 'subject', 'organization', 'program', 'icon', 'application', 'version', 'host', 'run', 'university', 'set', 'running', 'posting']\n",
      "topic-26 ['printer', 'disk', 'ram', 'print', 'port', 'window', 'machine', 'hardware', 'processor', 'modem', 'software', 'sale', 'line', 'shipping', 'chip']\n",
      "topic-27 ['car', 'line', 'driver', 'subject', 'organization', 'article', 'writes', 'saturn', 'dealer', 'engine', 'speed', 'price', 'model', 'good', 'toyota']\n",
      "topic-28 ['line', 'subject', 'sale', 'organization', 'detector', 'radar', 'car', 'oil', 'university', 'posting', 'host', 'nntp', 'writes', 'engine', 'price']\n",
      "topic-29 ['line', 'image', 'font', 'graphic', 'file', 'subject', 'organization', 'color', 'window', 'format', 'gif', 'program', 'animation', 'university', 'posting']\n",
      "topic-30 ['line', 'subject', 'organization', 'article', 'gordon', 'writes', 'bank', 'year', 'posting', 'doctor', 'host', 'nntp', 'pittsburgh', 'game', 'patient']\n",
      "topic-31 ['card', 'video', 'driver', 'vga', 'monitor', 'subject', 'organization', 'color', 'window', 'graphic', 'mode', 'vram', 'university', 'ati', 'vesa']\n",
      "topic-32 ['line', 'game', 'team', 'hockey', 'organization', 'subject', 'nhl', 'win', 'playoff', 'player', 'writes', 'article', 'play', 'goal', 'cup']\n",
      "topic-33 ['drive', 'scsi', 'disk', 'ide', 'hard', 'floppy', 'subject', 'organization', 'controller', 'mac', 'problem', 'file', 'boot', 'system', 'university']\n",
      "topic-34 ['bike', 'motorcycle', 'dod', 'subject', 'riding', 'organization', 'article', 'ride', 'writes', 'dog', 'rider', 'helmet', 'posting', 'nntp', 'host']\n",
      "topic-35 ['line', 'subject', 'organization', 'article', 'bank', 'writes', 'gordon', 'doctor', 'computer', 'people', 'reply', 'case', 'posting', 'government', 'information']\n",
      "topic-36 ['article', 'organization', 'subject', 'line', 'writes', 'bank', 'people', 'problem', 'computer', 'gordon', 'reply', 'work', 'medical', 'case', 'science']\n",
      "topic-37 ['line', 'organization', 'article', 'subject', 'writes', 'bank', 'gordon', 'doctor', 'people', 'reply', 'posting', 'medical', 'science', 'nntp', 'host']\n",
      "topic-38 ['god', 'christian', 'jesus', 'faith', 'belief', 'bible', 'people', 'truth', 'church', 'atheist', 'life', 'christianity', 'christ', 'scripture', 'existence']\n",
      "topic-39 ['team', 'line', 'game', 'year', 'hockey', 'writes', 'article', 'player', 'subject', 'organization', 'fan', 'playoff', 'bank', 'gordon', 'pittsburgh']\n",
      "topic-40 ['ram', 'disk', 'floppy', 'drive', 'port', 'memory', 'monitor', 'mouse', 'motherboard', 'meg', 'cache', 'modem', 'window', 'processor', 'video']\n",
      "topic-41 ['mac', 'modem', 'card', 'apple', 'subject', 'simms', 'organization', 'bus', 'motherboard', 'slot', 'ram', 'university', 'board', 'fpu', 'article']\n",
      "topic-42 ['team', 'game', 'hockey', 'playoff', 'season', 'player', 'fan', 'cup', 'stanley', 'win', 'play', 'nhl', 'toronto', 'league', 'baseball']\n",
      "topic-43 ['gun', 'armenian', 'line', 'firearm', 'people', 'turkish', 'handgun', 'armenia', 'weapon', 'argic', 'criminal', 'serdar', 'crime', 'arm', 'amendment']\n",
      "topic-44 ['line', 'subject', 'organization', 'writes', 'article', 'bank', 'gordon', 'game', 'team', 'year', 'doctor', 'posting', 'patient', 'clinton', 'disease']\n",
      "topic-45 ['israeli', 'israel', 'arab', 'jew', 'palestinian', 'greek', 'lebanese', 'turkish', 'writes', 'jewish', 'policy', 'peace', 'article', 'subject', 'people']\n",
      "topic-46 ['line', 'mouse', 'subject', 'organization', 'keyboard', 'port', 'amp', 'audio', 'university', 'channel', 'serial', 'sound', 'ground', 'host', 'input']\n",
      "topic-47 ['line', 'subject', 'organization', 'bmw', 'ticket', 'battery', 'article', 'posting', 'nntp', 'host', 'writes', 'university', 'launch', 'distribution', 'traffic']\n",
      "topic-48 ['line', 'subject', 'organization', 'gordon', 'article', 'bank', 'computer', 'writes', 'doctor', 'government', 'posting', 'system', 'reply', 'code', 'nntp']\n",
      "topic-49 ['line', 'team', 'game', 'writes', 'hockey', 'year', 'article', 'organization', 'subject', 'playoff', 'player', 'fan', 'pittsburgh', 'season', 'gordon']\n",
      "./\n",
      "[0.39739, 0.26096, 0.44367, 0.37272, 0.39977, 0.37253, 0.35129, 0.54088, 0.3701, 0.35852, 0.44212, 0.29989, 0.40067, 0.39405, 0.34638, 0.33156, 0.30945, 0.26626, 0.54088, 0.3742, 0.28578, 0.43923, 0.26626, 0.34056, 0.31594, 0.38825, 0.44988, 0.31108, 0.35866, 0.36013, 0.3496, 0.46163, 0.44438, 0.41254, 0.48323, 0.26041, 0.26183, 0.33554, 0.47648, 0.3241, 0.46561, 0.39934, 0.56003, 0.43148, 0.30161, 0.40643, 0.29335, 0.34771, 0.31918, 0.35433]\n",
      "0.3755574000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:00, 193.90it/s]\n",
      "59it [00:00, 287.81it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 284.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic_N': 50, 'CV_wiki': 0.3755574000000001, 'sim_w2v': 0.13726825836771653, 'diversity': 0.344, 'filename': 'results/240509_235837.txt', 'acc': 0.04580456718003186, 'macro-F1': 0.03911680615461721, 'Purity': 0.5132766861391397, 'NMI': 0.4881399747760182, 'label_match': 0.46057981262153086}\n",
      "\n",
      "Coeff   / regul: 1.00000 - recon: 1.00000 - c: 1.00000 - dist: 1.00000 \n",
      "Epoch-0 / recon: 2.86565 - dist: 0.08903 - cons: -0.26928\n",
      "Epoch-1 / recon: 2.75951 - dist: 0.06914 - cons: -0.31323\n",
      "Epoch-2 / recon: 2.70354 - dist: 0.06186 - cons: -0.33037\n",
      "Epoch-3 / recon: 2.67056 - dist: 0.05792 - cons: -0.34050\n",
      "Epoch-4 / recon: 2.64936 - dist: 0.05547 - cons: -0.34662\n",
      "Epoch-5 / recon: 2.63447 - dist: 0.05364 - cons: -0.35124\n",
      "Epoch-6 / recon: 2.62334 - dist: 0.05231 - cons: -0.35462\n",
      "Epoch-7 / recon: 2.61460 - dist: 0.05132 - cons: -0.35762\n",
      "Epoch-8 / recon: 2.60775 - dist: 0.05050 - cons: -0.36007\n",
      "Epoch-9 / recon: 2.60221 - dist: 0.04986 - cons: -0.36155\n",
      "Epoch-10 / recon: 2.59761 - dist: 0.04934 - cons: -0.36285\n",
      "Epoch-11 / recon: 2.59367 - dist: 0.04886 - cons: -0.36434\n",
      "Epoch-12 / recon: 2.59040 - dist: 0.04843 - cons: -0.36552\n",
      "Epoch-13 / recon: 2.58754 - dist: 0.04813 - cons: -0.36657\n",
      "Epoch-14 / recon: 2.58506 - dist: 0.04778 - cons: -0.36758\n",
      "Epoch-15 / recon: 2.58290 - dist: 0.04754 - cons: -0.36821\n",
      "Epoch-16 / recon: 2.58096 - dist: 0.04731 - cons: -0.36890\n",
      "Epoch-17 / recon: 2.57923 - dist: 0.04710 - cons: -0.36961\n",
      "Epoch-18 / recon: 2.57770 - dist: 0.04692 - cons: -0.37009\n",
      "Epoch-19 / recon: 2.57630 - dist: 0.04673 - cons: -0.37070\n",
      "Epoch-20 / recon: 2.57494 - dist: 0.04654 - cons: -0.37136\n",
      "Epoch-21 / recon: 2.57374 - dist: 0.04635 - cons: -0.37191\n",
      "Epoch-22 / recon: 2.57261 - dist: 0.04619 - cons: -0.37243\n",
      "Epoch-23 / recon: 2.57162 - dist: 0.04606 - cons: -0.37286\n",
      "Epoch-24 / recon: 2.57064 - dist: 0.04590 - cons: -0.37340\n",
      "Epoch-25 / recon: 2.56974 - dist: 0.04580 - cons: -0.37379\n",
      "Epoch-26 / recon: 2.56892 - dist: 0.04570 - cons: -0.37424\n",
      "Epoch-27 / recon: 2.56814 - dist: 0.04558 - cons: -0.37464\n",
      "Epoch-28 / recon: 2.56743 - dist: 0.04550 - cons: -0.37495\n",
      "Epoch-29 / recon: 2.56676 - dist: 0.04542 - cons: -0.37531\n",
      "Epoch-30 / recon: 2.56614 - dist: 0.04531 - cons: -0.37563\n",
      "Epoch-31 / recon: 2.56553 - dist: 0.04524 - cons: -0.37584\n",
      "Epoch-32 / recon: 2.56499 - dist: 0.04515 - cons: -0.37616\n",
      "Epoch-33 / recon: 2.56448 - dist: 0.04509 - cons: -0.37645\n",
      "Epoch-34 / recon: 2.56399 - dist: 0.04504 - cons: -0.37665\n",
      "Epoch-35 / recon: 2.56352 - dist: 0.04498 - cons: -0.37696\n",
      "Epoch-36 / recon: 2.56306 - dist: 0.04492 - cons: -0.37715\n",
      "Epoch-37 / recon: 2.56264 - dist: 0.04487 - cons: -0.37736\n",
      "Epoch-38 / recon: 2.56223 - dist: 0.04483 - cons: -0.37757\n",
      "Epoch-39 / recon: 2.56183 - dist: 0.04477 - cons: -0.37779\n",
      "Epoch-40 / recon: 2.56149 - dist: 0.04472 - cons: -0.37800\n",
      "Epoch-41 / recon: 2.56111 - dist: 0.04466 - cons: -0.37826\n",
      "Epoch-42 / recon: 2.56077 - dist: 0.04461 - cons: -0.37845\n",
      "Epoch-43 / recon: 2.56045 - dist: 0.04457 - cons: -0.37866\n",
      "Epoch-44 / recon: 2.56013 - dist: 0.04453 - cons: -0.37881\n",
      "Epoch-45 / recon: 2.55977 - dist: 0.04443 - cons: -0.37912\n",
      "Epoch-46 / recon: 2.55934 - dist: 0.04432 - cons: -0.37945\n",
      "Epoch-47 / recon: 2.55893 - dist: 0.04421 - cons: -0.37982\n",
      "Epoch-48 / recon: 2.55853 - dist: 0.04411 - cons: -0.38020\n",
      "Epoch-49 / recon: 2.55813 - dist: 0.04401 - cons: -0.38049\n",
      "------- Evaluation results -------\n",
      "topic-0 ['line', 'subject', 'organization', 'drive', 'scsi', 'writes', 'article', 'posting', 'nntp', 'host', 'disk', 'university', 'gordon', 'bank', 'reply']\n",
      "topic-1 ['key', 'clipper', 'chip', 'subject', 'organization', 'phone', 'encryption', 'internet', 'escrow', 'host', 'posting', 'nntp', 'mail', 'number', 'system']\n",
      "topic-2 ['line', 'drive', 'organization', 'subject', 'scsi', 'writes', 'article', 'posting', 'host', 'nntp', 'disk', 'university', 'gordon', 'reply', 'bank']\n",
      "topic-3 ['line', 'organization', 'subject', 'drive', 'host', 'nntp', 'window', 'posting', 'disk', 'scsi', 'university', 'distribution', 'system', 'gordon', 'problem']\n",
      "topic-4 ['line', 'detector', 'radar', 'subject', 'ticket', 'organization', 'sale', 'battery', 'oil', 'university', 'posting', 'nntp', 'host', 'car', 'writes']\n",
      "topic-5 ['line', 'organization', 'subject', 'drive', 'scsi', 'writes', 'article', 'university', 'posting', 'host', 'disk', 'nntp', 'gordon', 'bank', 'reply']\n",
      "topic-6 ['car', 'line', 'driver', 'subject', 'organization', 'article', 'writes', 'dealer', 'saturn', 'toyota', 'engine', 'speed', 'good', 'price', 'model']\n",
      "topic-7 ['line', 'subject', 'organization', 'writes', 'article', 'scsi', 'god', 'drive', 'people', 'university', 'posting', 'gordon', 'bank', 'host', 'nntp']\n",
      "topic-8 ['line', 'drive', 'scsi', 'disk', 'subject', 'organization', 'article', 'writes', 'university', 'gordon', 'people', 'posting', 'host', 'nntp', 'bank']\n",
      "topic-9 ['line', 'drive', 'organization', 'subject', 'scsi', 'disk', 'posting', 'nntp', 'host', 'window', 'university', 'distribution', 'article', 'computer', 'problem']\n",
      "topic-10 ['line', 'organization', 'subject', 'drive', 'writes', 'article', 'scsi', 'university', 'posting', 'gordon', 'disk', 'host', 'bank', 'nntp', 'people']\n",
      "topic-11 ['morality', 'objective', 'homosexual', 'writes', 'atheist', 'gay', 'keith', 'moral', 'subject', 'people', 'article', 'islamic', 'islam', 'organization', 'sex']\n",
      "topic-12 ['line', 'subject', 'organization', 'writes', 'article', 'drive', 'scsi', 'people', 'university', 'god', 'posting', 'host', 'nntp', 'gordon', 'msg']\n",
      "topic-13 ['line', 'drive', 'organization', 'subject', 'scsi', 'posting', 'host', 'disk', 'article', 'writes', 'nntp', 'university', 'problem', 'gordon', 'distribution']\n",
      "topic-14 ['line', 'drive', 'organization', 'subject', 'disk', 'scsi', 'posting', 'host', 'nntp', 'article', 'system', 'problem', 'writes', 'university', 'gordon']\n",
      "topic-15 ['space', 'line', 'moon', 'orbit', 'nasa', 'subject', 'organization', 'spacecraft', 'earth', 'writes', 'article', 'satellite', 'lunar', 'billion', 'year']\n",
      "topic-16 ['mac', 'modem', 'card', 'apple', 'subject', 'organization', 'bus', 'simms', 'motherboard', 'slot', 'ram', 'board', 'university', 'controller', 'vlb']\n",
      "topic-17 ['israeli', 'israel', 'arab', 'jew', 'palestinian', 'greek', 'writes', 'lebanese', 'jewish', 'policy', 'turkish', 'peace', 'palestine', 'people', 'article']\n",
      "topic-18 ['line', 'subject', 'organization', 'university', 'posting', 'nntp', 'host', 'point', 'article', 'algorithm', 'valley', 'distribution', 'writes', 'group', 'usa']\n",
      "topic-19 ['card', 'video', 'driver', 'vga', 'monitor', 'color', 'window', 'subject', 'graphic', 'organization', 'vram', 'mode', 'ati', 'vesa', 'svga']\n",
      "topic-20 ['god', 'christian', 'jesus', 'people', 'faith', 'bible', 'belief', 'truth', 'atheist', 'life', 'christianity', 'church', 'scripture', 'christ', 'thing']\n",
      "topic-21 ['printer', 'file', 'subject', 'color', 'image', 'organization', 'window', 'gif', 'university', 'format', 'nntp', 'posting', 'print', 'host', 'bmp']\n",
      "topic-22 ['line', 'mouse', 'subject', 'port', 'organization', 'amp', 'keyboard', 'channel', 'audio', 'input', 'sound', 'university', 'serial', 'ground', 'stereo']\n",
      "topic-23 ['max', 'line', 'batf', 'fbi', 'weapon', 'organization', 'waco', 'writes', 'subject', 'people', 'article', 'gun', 'law', 'government', 'fire']\n",
      "topic-24 ['line', 'writes', 'organization', 'subject', 'article', 'atf', 'dividian', 'people', 'ranch', 'god', 'posting', 'death', 'university', 'burn', 'nntp']\n",
      "topic-25 ['line', 'subject', 'organization', 'drive', 'article', 'writes', 'scsi', 'posting', 'university', 'host', 'nntp', 'disk', 'gordon', 'reply', 'bank']\n",
      "topic-26 ['game', 'subject', 'organization', 'team', 'win', 'playoff', 'detroit', 'university', 'wing', 'espn', 'toronto', 'cup', 'posting', 'fan', 'player']\n",
      "topic-27 ['line', 'drive', 'subject', 'organization', 'scsi', 'writes', 'article', 'university', 'posting', 'host', 'disk', 'nntp', 'gordon', 'bank', 'reply']\n",
      "topic-28 ['window', 'widget', 'manager', 'file', 'program', 'application', 'motif', 'subject', 'organization', 'icon', 'running', 'problem', 'run', 'set', 'host']\n",
      "topic-29 ['line', 'subject', 'organization', 'drive', 'scsi', 'writes', 'article', 'posting', 'host', 'university', 'nntp', 'gordon', 'disk', 'reply', 'bank']\n",
      "topic-30 ['line', 'organization', 'subject', 'drive', 'writes', 'scsi', 'article', 'host', 'university', 'posting', 'disk', 'nntp', 'gordon', 'bank', 'problem']\n",
      "topic-31 ['baseball', 'team', 'game', 'player', 'jewish', 'year', 'subject', 'organization', 'pitcher', 'phillies', 'season', 'article', 'writes', 'pitching', 'hit']\n",
      "topic-32 ['line', 'drive', 'organization', 'subject', 'scsi', 'writes', 'article', 'disk', 'university', 'posting', 'gordon', 'host', 'problem', 'nntp', 'msg']\n",
      "topic-33 ['line', 'drive', 'organization', 'subject', 'scsi', 'host', 'posting', 'disk', 'nntp', 'article', 'university', 'distribution', 'computer', 'writes', 'gordon']\n",
      "topic-34 ['line', 'organization', 'drive', 'subject', 'scsi', 'host', 'posting', 'nntp', 'university', 'disk', 'article', 'distribution', 'writes', 'system', 'reply']\n",
      "topic-35 ['line', 'subject', 'organization', 'drive', 'disk', 'posting', 'host', 'scsi', 'nntp', 'university', 'distribution', 'bmw', 'gordon', 'msg', 'computer']\n",
      "topic-36 ['line', 'drive', 'window', 'organization', 'subject', 'disk', 'host', 'nntp', 'posting', 'scsi', 'system', 'distribution', 'computer', 'sale', 'program']\n",
      "topic-37 ['line', 'drive', 'scsi', 'subject', 'organization', 'disk', 'article', 'writes', 'university', 'hard', 'problem', 'posting', 'host', 'nntp', 'bank']\n",
      "topic-38 ['team', 'hockey', 'nhl', 'player', 'game', 'play', 'goal', 'season', 'subject', 'organization', 'playoff', 'period', 'league', 'traded', 'captain']\n",
      "topic-39 ['line', 'drive', 'window', 'organization', 'disk', 'subject', 'host', 'nntp', 'scsi', 'posting', 'system', 'distribution', 'computer', 'file', 'university']\n",
      "topic-40 ['line', 'drive', 'subject', 'disk', 'organization', 'window', 'host', 'scsi', 'posting', 'nntp', 'system', 'distribution', 'sale', 'problem', 'file']\n",
      "topic-41 ['line', 'subject', 'organization', 'drive', 'writes', 'article', 'scsi', 'posting', 'host', 'university', 'nntp', 'disk', 'gordon', 'people', 'bank']\n",
      "topic-42 ['line', 'god', 'christian', 'jesus', 'bible', 'subject', 'organization', 'church', 'christ', 'writes', 'book', 'university', 'article', 'sin', 'people']\n",
      "topic-43 ['font', 'graphic', 'subject', 'organization', 'image', 'window', 'animation', 'package', 'program', 'host', 'posting', 'nntp', 'university', 'drawing', 'file']\n",
      "topic-44 ['gun', 'armenian', 'firearm', 'people', 'turkish', 'handgun', 'armenia', 'weapon', 'argic', 'criminal', 'serdar', 'crime', 'genocide', 'control', 'soviet']\n",
      "topic-45 ['line', 'monitor', 'scsi', 'screen', 'msg', 'logo', 'startup', 'christian', 'drive', 'disease', 'food', 'nec', 'patient', 'disk', 'gordon']\n",
      "topic-46 ['line', 'drive', 'organization', 'subject', 'writes', 'scsi', 'article', 'disk', 'university', 'people', 'posting', 'host', 'nntp', 'msg', 'bank']\n",
      "topic-47 ['line', 'organization', 'subject', 'drive', 'writes', 'scsi', 'article', 'university', 'posting', 'host', 'nntp', 'disk', 'gordon', 'people', 'msg']\n",
      "topic-48 ['bike', 'line', 'dod', 'motorcycle', 'riding', 'ride', 'organization', 'subject', 'article', 'dog', 'writes', 'helmet', 'rider', 'posting', 'nntp']\n",
      "topic-49 ['key', 'line', 'government', 'chip', 'encryption', 'clipper', 'nsa', 'clinton', 'bit', 'tapped', 'wiretap', 'escrow', 'system', 'secure', 'people']\n",
      "./\n",
      "[0.37695, 0.38719, 0.37695, 0.39381, 0.36515, 0.37695, 0.31108, 0.37793, 0.38253, 0.38617, 0.38253, 0.31594, 0.38223, 0.37091, 0.36875, 0.39977, 0.42868, 0.45013, 0.33063, 0.48533, 0.47528, 0.41278, 0.30889, 0.35154, 0.34394, 0.37695, 0.40212, 0.37695, 0.37992, 0.37695, 0.37113, 0.42672, 0.38163, 0.37168, 0.36754, 0.41599, 0.37698, 0.37126, 0.49608, 0.39219, 0.37595, 0.38253, 0.35349, 0.40145, 0.44793, 0.42308, 0.39315, 0.39297, 0.47498, 0.34611]\n",
      "0.38835539999999985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:00, 200.90it/s]\n",
      "59it [00:00, 281.85it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 263.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic_N': 50, 'CV_wiki': 0.38835539999999985, 'sim_w2v': 0.11422481640695953, 'diversity': 0.3, 'filename': 'results/240510_000146.txt', 'acc': 0.020578863515666488, 'macro-F1': 0.014714544879857567, 'Purity': 0.5103558151885289, 'NMI': 0.4826379132355541, 'label_match': 0.4292911437157504}\n",
      "\n",
      "Coeff   / regul: 1.00000 - recon: 1.00000 - c: 1.00000 - dist: 1.00000 \n",
      "Epoch-0 / recon: 2.86267 - dist: 0.07934 - cons: -0.27902\n",
      "Epoch-1 / recon: 2.75148 - dist: 0.06009 - cons: -0.32727\n",
      "Epoch-2 / recon: 2.69233 - dist: 0.05348 - cons: -0.34603\n",
      "Epoch-3 / recon: 2.65752 - dist: 0.05004 - cons: -0.35642\n",
      "Epoch-4 / recon: 2.63523 - dist: 0.04789 - cons: -0.36339\n",
      "Epoch-5 / recon: 2.61926 - dist: 0.04619 - cons: -0.36889\n",
      "Epoch-6 / recon: 2.60745 - dist: 0.04482 - cons: -0.37331\n",
      "Epoch-7 / recon: 2.59835 - dist: 0.04378 - cons: -0.37698\n",
      "Epoch-8 / recon: 2.59114 - dist: 0.04298 - cons: -0.38001\n",
      "Epoch-9 / recon: 2.58535 - dist: 0.04233 - cons: -0.38237\n",
      "Epoch-10 / recon: 2.58044 - dist: 0.04183 - cons: -0.38452\n",
      "Epoch-11 / recon: 2.57629 - dist: 0.04135 - cons: -0.38639\n",
      "Epoch-12 / recon: 2.57277 - dist: 0.04095 - cons: -0.38798\n",
      "Epoch-13 / recon: 2.56966 - dist: 0.04062 - cons: -0.38945\n",
      "Epoch-14 / recon: 2.56684 - dist: 0.04032 - cons: -0.39081\n",
      "Epoch-15 / recon: 2.56434 - dist: 0.04005 - cons: -0.39212\n",
      "Epoch-16 / recon: 2.56220 - dist: 0.03978 - cons: -0.39341\n",
      "Epoch-17 / recon: 2.56030 - dist: 0.03958 - cons: -0.39419\n",
      "Epoch-18 / recon: 2.55859 - dist: 0.03942 - cons: -0.39502\n",
      "Epoch-19 / recon: 2.55709 - dist: 0.03923 - cons: -0.39577\n",
      "Epoch-20 / recon: 2.55572 - dist: 0.03910 - cons: -0.39637\n",
      "Epoch-21 / recon: 2.55440 - dist: 0.03896 - cons: -0.39712\n",
      "Epoch-22 / recon: 2.55322 - dist: 0.03883 - cons: -0.39775\n",
      "Epoch-23 / recon: 2.55213 - dist: 0.03872 - cons: -0.39821\n",
      "Epoch-24 / recon: 2.55108 - dist: 0.03857 - cons: -0.39882\n",
      "Epoch-25 / recon: 2.55009 - dist: 0.03842 - cons: -0.39935\n",
      "Epoch-26 / recon: 2.54917 - dist: 0.03830 - cons: -0.39992\n",
      "Epoch-27 / recon: 2.54838 - dist: 0.03820 - cons: -0.40034\n",
      "Epoch-28 / recon: 2.54757 - dist: 0.03809 - cons: -0.40074\n",
      "Epoch-29 / recon: 2.54682 - dist: 0.03798 - cons: -0.40115\n",
      "Epoch-30 / recon: 2.54609 - dist: 0.03787 - cons: -0.40162\n",
      "Epoch-31 / recon: 2.54546 - dist: 0.03778 - cons: -0.40184\n",
      "Epoch-32 / recon: 2.54483 - dist: 0.03769 - cons: -0.40225\n",
      "Epoch-33 / recon: 2.54424 - dist: 0.03760 - cons: -0.40254\n",
      "Epoch-34 / recon: 2.54367 - dist: 0.03751 - cons: -0.40285\n",
      "Epoch-35 / recon: 2.54312 - dist: 0.03743 - cons: -0.40324\n",
      "Epoch-36 / recon: 2.54263 - dist: 0.03736 - cons: -0.40351\n",
      "Epoch-37 / recon: 2.54212 - dist: 0.03727 - cons: -0.40381\n",
      "Epoch-38 / recon: 2.54167 - dist: 0.03722 - cons: -0.40402\n",
      "Epoch-39 / recon: 2.54126 - dist: 0.03717 - cons: -0.40421\n",
      "Epoch-40 / recon: 2.54084 - dist: 0.03710 - cons: -0.40451\n",
      "Epoch-41 / recon: 2.54045 - dist: 0.03703 - cons: -0.40486\n",
      "Epoch-42 / recon: 2.54007 - dist: 0.03697 - cons: -0.40512\n",
      "Epoch-43 / recon: 2.53969 - dist: 0.03692 - cons: -0.40535\n",
      "Epoch-44 / recon: 2.53935 - dist: 0.03687 - cons: -0.40555\n",
      "Epoch-45 / recon: 2.53901 - dist: 0.03684 - cons: -0.40570\n",
      "Epoch-46 / recon: 2.53870 - dist: 0.03679 - cons: -0.40595\n",
      "Epoch-47 / recon: 2.53841 - dist: 0.03675 - cons: -0.40620\n",
      "Epoch-48 / recon: 2.53812 - dist: 0.03671 - cons: -0.40639\n",
      "Epoch-49 / recon: 2.53785 - dist: 0.03667 - cons: -0.40657\n",
      "------- Evaluation results -------\n",
      "topic-0 ['organization', 'subject', 'line', 'university', 'writes', 'article', 'posting', 'nntp', 'modem', 'host', 'mac', 'mouse', 'card', 'simms', 'board']\n",
      "topic-1 ['morality', 'objective', 'homosexual', 'writes', 'atheist', 'gay', 'keith', 'moral', 'people', 'subject', 'islam', 'article', 'islamic', 'organization', 'sexual']\n",
      "topic-2 ['line', 'gordon', 'bank', 'doctor', 'disease', 'patient', 'subject', 'organization', 'article', 'medical', 'pain', 'writes', 'pittsburgh', 'treatment', 'shameful']\n",
      "topic-3 ['line', 'subject', 'organization', 'university', 'posting', 'point', 'nntp', 'host', 'article', 'writes', 'valley', 'algorithm', 'group', 'distribution', 'reply']\n",
      "topic-4 ['organization', 'line', 'subject', 'university', 'card', 'system', 'host', 'posting', 'nntp', 'modem', 'distribution', 'mac', 'apple', 'article', 'writes']\n",
      "topic-5 ['organization', 'subject', 'line', 'university', 'writes', 'article', 'posting', 'modem', 'host', 'mac', 'nntp', 'card', 'mouse', 'work', 'system']\n",
      "topic-6 ['line', 'subject', 'mac', 'organization', 'card', 'modem', 'apple', 'mouse', 'port', 'posting', 'sale', 'host', 'nntp', 'board', 'simms']\n",
      "topic-7 ['line', 'window', 'drive', 'disk', 'software', 'sale', 'mac', 'modem', 'machine', 'memory', 'apple', 'monitor', 'mouse', 'port', 'card']\n",
      "topic-8 ['line', 'subject', 'organization', 'university', 'posting', 'nntp', 'host', 'mac', 'modem', 'mouse', 'apple', 'article', 'card', 'writes', 'distribution']\n",
      "topic-9 ['line', 'mac', 'window', 'card', 'sale', 'port', 'apple', 'modem', 'drive', 'disk', 'subject', 'mouse', 'organization', 'software', 'memory']\n",
      "topic-10 ['file', 'image', 'subject', 'organization', 'gif', 'font', 'format', 'ftp', 'window', 'bmp', 'animation', 'host', 'nntp', 'program', 'posting']\n",
      "topic-11 ['organization', 'subject', 'line', 'university', 'writes', 'article', 'posting', 'nntp', 'host', 'card', 'mac', 'modem', 'system', 'work', 'board']\n",
      "topic-12 ['line', 'organization', 'subject', 'card', 'university', 'posting', 'mouse', 'modem', 'host', 'mac', 'nntp', 'apple', 'port', 'sale', 'window']\n",
      "topic-13 ['line', 'window', 'sale', 'mac', 'mouse', 'modem', 'port', 'apple', 'subject', 'software', 'mail', 'card', 'serial', 'organization', 'machine']\n",
      "topic-14 ['line', 'organization', 'subject', 'university', 'posting', 'host', 'nntp', 'card', 'system', 'mouse', 'mac', 'computer', 'article', 'writes', 'chip']\n",
      "topic-15 ['car', 'line', 'article', 'writes', 'driver', 'subject', 'organization', 'engine', 'speed', 'saturn', 'dealer', 'price', 'good', 'model', 'toyota']\n",
      "topic-16 ['line', 'organization', 'subject', 'university', 'modem', 'card', 'mac', 'posting', 'writes', 'article', 'host', 'mouse', 'nntp', 'apple', 'board']\n",
      "topic-17 ['bike', 'line', 'dod', 'motorcycle', 'article', 'organization', 'riding', 'writes', 'subject', 'ride', 'dog', 'helmet', 'rider', 'posting', 'nntp']\n",
      "topic-18 ['line', 'drive', 'card', 'organization', 'subject', 'disk', 'sale', 'mac', 'window', 'modem', 'mouse', 'apple', 'posting', 'host', 'port']\n",
      "topic-19 ['team', 'hockey', 'nhl', 'player', 'game', 'play', 'goal', 'season', 'playoff', 'period', 'traded', 'captain', 'subject', 'league', 'organization']\n",
      "topic-20 ['subject', 'organization', 'line', 'university', 'system', 'posting', 'host', 'nntp', 'work', 'writes', 'card', 'article', 'problem', 'modem', 'chip']\n",
      "topic-21 ['subject', 'organization', 'line', 'university', 'article', 'posting', 'writes', 'nntp', 'host', 'problem', 'card', 'modem', 'mouse', 'sale', 'system']\n",
      "topic-22 ['line', 'subject', 'organization', 'mac', 'modem', 'card', 'apple', 'university', 'posting', 'bus', 'mouse', 'host', 'nntp', 'board', 'sale']\n",
      "topic-23 ['line', 'organization', 'subject', 'card', 'mac', 'modem', 'system', 'university', 'apple', 'host', 'posting', 'nntp', 'mouse', 'sale', 'bus']\n",
      "topic-24 ['line', 'monitor', 'window', 'widget', 'screen', 'subject', 'organization', 'display', 'problem', 'motif', 'host', 'color', 'nntp', 'posting', 'computer']\n",
      "topic-25 ['chip', 'key', 'clipper', 'subject', 'organization', 'phone', 'encryption', 'escrow', 'internet', 'posting', 'host', 'nntp', 'mail', 'system', 'number']\n",
      "topic-26 ['israeli', 'israel', 'arab', 'jew', 'palestinian', 'policy', 'writes', 'greek', 'lebanese', 'peace', 'turkish', 'jewish', 'article', 'people', 'civilian']\n",
      "topic-27 ['line', 'subject', 'organization', 'sale', 'car', 'radar', 'detector', 'oil', 'posting', 'university', 'nntp', 'host', 'article', 'writes', 'distribution']\n",
      "topic-28 ['key', 'government', 'chip', 'encryption', 'line', 'clipper', 'nsa', 'wiretap', 'clinton', 'people', 'tapped', 'crypto', 'escrow', 'secure', 'bit']\n",
      "topic-29 ['drive', 'scsi', 'disk', 'ide', 'hard', 'floppy', 'controller', 'subject', 'organization', 'mac', 'problem', 'boot', 'file', 'system', 'tape']\n",
      "topic-30 ['line', 'window', 'subject', 'organization', 'system', 'god', 'host', 'sale', 'nntp', 'posting', 'card', 'distribution', 'university', 'mac', 'christian']\n",
      "topic-31 ['game', 'subject', 'organization', 'win', 'team', 'detroit', 'playoff', 'wing', 'espn', 'university', 'toronto', 'writes', 'posting', 'cup', 'fan']\n",
      "topic-32 ['baseball', 'player', 'team', 'game', 'year', 'jewish', 'phillies', 'pitcher', 'subject', 'organization', 'season', 'hit', 'pitching', 'article', 'writes']\n",
      "topic-33 ['line', 'subject', 'organization', 'university', 'system', 'writes', 'posting', 'article', 'nntp', 'host', 'work', 'problem', 'card', 'good', 'distribution']\n",
      "topic-34 ['msg', 'line', 'food', 'drug', 'article', 'writes', 'subject', 'organization', 'air', 'people', 'water', 'sensitivity', 'nuclear', 'superstition', 'circuit']\n",
      "topic-35 ['card', 'video', 'driver', 'vga', 'monitor', 'subject', 'organization', 'graphic', 'color', 'window', 'mode', 'vram', 'ati', 'svga', 'vesa']\n",
      "topic-36 ['god', 'christian', 'jesus', 'people', 'faith', 'bible', 'belief', 'life', 'truth', 'atheist', 'christianity', 'church', 'christ', 'thing', 'scripture']\n",
      "topic-37 ['god', 'christian', 'jesus', 'bible', 'church', 'christ', 'subject', 'organization', 'sin', 'writes', 'book', 'roman', 'christianity', 'article', 'people']\n",
      "topic-38 ['line', 'subject', 'organization', 'ticket', 'bmw', 'battery', 'writes', 'posting', 'nntp', 'host', 'article', 'university', 'launch', 'traffic', 'lib']\n",
      "topic-39 ['gun', 'armenian', 'firearm', 'line', 'people', 'turkish', 'handgun', 'weapon', 'armenia', 'argic', 'criminal', 'serdar', 'crime', 'amendment', 'law']\n",
      "topic-40 ['line', 'printer', 'graphic', 'color', 'window', 'subject', 'organization', 'font', 'print', 'university', 'posting', 'package', 'problem', 'canon', 'host']\n",
      "topic-41 ['window', 'file', 'subject', 'organization', 'manager', 'program', 'icon', 'host', 'application', 'posting', 'nntp', 'running', 'set', 'version', 'run']\n",
      "topic-42 ['line', 'window', 'mac', 'sale', 'modem', 'apple', 'port', 'card', 'mouse', 'disk', 'software', 'drive', 'subject', 'ram', 'organization']\n",
      "topic-43 ['organization', 'subject', 'writes', 'university', 'article', 'line', 'posting', 'host', 'nntp', 'good', 'work', 'system', 'mouse', 'distribution', 'pin']\n",
      "topic-44 ['line', 'widget', 'radar', 'mouse', 'modem', 'simms', 'motherboard', 'detector', 'irq', 'mac', 'port', 'amp', 'bus', 'fpu', 'serial']\n",
      "topic-45 ['line', 'window', 'disk', 'sale', 'drive', 'monitor', 'software', 'car', 'mac', 'video', 'apple', 'shipping', 'modem', 'card', 'port']\n",
      "topic-46 ['space', 'line', 'orbit', 'moon', 'subject', 'organization', 'nasa', 'writes', 'spacecraft', 'article', 'earth', 'billion', 'year', 'shuttle', 'station']\n",
      "topic-47 ['line', 'window', 'disk', 'sale', 'monitor', 'software', 'video', 'drive', 'mac', 'shipping', 'car', 'apple', 'mail', 'program', 'package']\n",
      "topic-48 ['line', 'disk', 'window', 'drive', 'monitor', 'sale', 'car', 'software', 'scsi', 'floppy', 'video', 'shipping', 'mac', 'program', 'apple']\n",
      "topic-49 ['max', 'line', 'fbi', 'writes', 'batf', 'atf', 'people', 'article', 'waco', 'organization', 'subject', 'fire', 'trial', 'government', 'law']\n",
      "./\n",
      "[0.35465, 0.3212, 0.32937, 0.32991, 0.34824, 0.33432, 0.38139, 0.34701, 0.35984, 0.33687, 0.43133, 0.32939, 0.38665, 0.31938, 0.34354, 0.31108, 0.36211, 0.47498, 0.35309, 0.49608, 0.33052, 0.33433, 0.39139, 0.38537, 0.37011, 0.38719, 0.41551, 0.34133, 0.38219, 0.40904, 0.36145, 0.37168, 0.42672, 0.31798, 0.31549, 0.48533, 0.47528, 0.39389, 0.35559, 0.43289, 0.35209, 0.40619, 0.34185, 0.32755, 0.4797, 0.36833, 0.37532, 0.34973, 0.41686, 0.36591]\n",
      "0.3743447999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:00, 207.46it/s]\n",
      "59it [00:00, 308.90it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 273.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic_N': 50, 'CV_wiki': 0.3743447999999999, 'sim_w2v': 0.11788714024287275, 'diversity': 0.32, 'filename': 'results/240510_000435.txt', 'acc': 0.027748274030801913, 'macro-F1': 0.020221399226255706, 'Purity': 0.5165958576739246, 'NMI': 0.4949721449785493, 'label_match': 0.4359200989923988}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation import evaluate_classification, evaluate_clustering\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for i in range(args.stage_2_repeat):\n",
    "    model = ContBertTopicExtractorAE(N_topic=n_topic, N_word=args.n_word, bert=bert_name, bert_dim=768)\n",
    "    model.load_state_dict(torch.load(model_stage1_name), strict=True)\n",
    "    model.beta = nn.Parameter(torch.Tensor(model.N_topic, n_word))\n",
    "    nn.init.xavier_uniform_(model.beta)\n",
    "    model.beta_batchnorm = nn.Sequential()\n",
    "    model.cuda(gpu_ids[0])\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    dlosses = AverageMeter() \n",
    "    rlosses = AverageMeter()\n",
    "    closses = AverageMeter()\n",
    "    distlosses = AverageMeter()\n",
    "    trainloader = DataLoader(finetuneds, batch_size=bsz, shuffle=True, num_workers=0)\n",
    "    testloader = DataLoader(testds2, batch_size=bsz, shuffle=False, num_workers=0)\n",
    "    memoryloader = DataLoader(finetuneds, batch_size=bsz * 2, shuffle=False, num_workers=0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.stage_2_lr)\n",
    "\n",
    "    memory_queue = F.softmax(torch.randn(512, n_topic).cuda(gpu_ids[0]), dim=1)\n",
    "    print(\"Coeff   / regul: {:.5f} - recon: {:.5f} - c: {:.5f} - dist: {:.5f} \".format(args.coeff_2_regul, \n",
    "                                                                                        args.coeff_2_recon,\n",
    "                                                                                        args.coeff_2_cons,\n",
    "                                                                                        args.coeff_2_dist))\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        model.encoder.eval()\n",
    "        for batch_idx, batch in enumerate(trainloader):\n",
    "            org_input, pos_input, org_bow, pos_bow = batch\n",
    "            org_input = org_input.cuda(gpu_ids[0])\n",
    "            org_bow = org_bow.cuda(gpu_ids[0])\n",
    "            pos_input = pos_input.cuda(gpu_ids[0])\n",
    "            pos_bow = pos_bow.cuda(gpu_ids[0])\n",
    "\n",
    "            batch_size = org_input_ids.size(0)\n",
    "\n",
    "            org_dists, org_topic_logit = model.decode(org_input)\n",
    "            pos_dists, pos_topic_logit = model.decode(pos_input)\n",
    "\n",
    "            org_topic = F.softmax(org_topic_logit, dim=1)\n",
    "            pos_topic = F.softmax(pos_topic_logit, dim=1)\n",
    "\n",
    "            # reconstruction loss\n",
    "            # batchmean\n",
    "#             org_target = torch.matmul(org_topic.detach(), weight_cands)\n",
    "#             pos_target = torch.matmul(pos_topic.detach(), weight_cands)\n",
    "            \n",
    "#             _, org_target = torch.max(org_topic.detach(), 1)\n",
    "#             _, pos_target = torch.max(pos_topic.detach(), 1)\n",
    "            \n",
    "            recons_loss = torch.mean(-torch.sum(torch.log(org_dists + 1E-10) * (org_bow * weight_cands), axis=1), axis=0)\n",
    "            recons_loss += torch.mean(-torch.sum(torch.log((1-org_dists) + 1E-10) * ((1-org_bow) * weight_cands), axis=1), axis=0)\n",
    "            recons_loss += torch.mean(-torch.sum(torch.log(pos_dists + 1E-10) * (pos_bow * weight_cands), axis=1), axis=0)\n",
    "            recons_loss += torch.mean(-torch.sum(torch.log((1-pos_dists) + 1E-10) * ((1-pos_bow) * weight_cands), axis=1), axis=0)\n",
    "            recons_loss *= 0.5\n",
    "\n",
    "            # consistency loss\n",
    "            pos_sim = torch.sum(org_topic * pos_topic, dim=-1)\n",
    "            cons_loss = -pos_sim.mean()\n",
    "\n",
    "            # distribution loss\n",
    "            # batchmean\n",
    "            distmatch_loss = dist_match_loss(torch.cat((org_topic, pos_topic), dim=0), dirichlet_alpha_2)\n",
    "            \n",
    "\n",
    "            loss = args.coeff_2_recon * recons_loss + \\\n",
    "                   args.coeff_2_cons * cons_loss + \\\n",
    "                   args.coeff_2_dist * distmatch_loss \n",
    "            \n",
    "            losses.update(loss.item(), bsz)\n",
    "            closses.update(cons_loss.item(), bsz)\n",
    "            rlosses.update(recons_loss.item(), bsz)\n",
    "            distlosses.update(distmatch_loss.item(), bsz)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(\"Epoch-{} / recon: {:.5f} - dist: {:.5f} - cons: {:.5f}\".format(epoch, rlosses.avg, distlosses.avg, closses.avg))\n",
    "\n",
    "    print(\"------- Evaluation results -------\")\n",
    "    all_list = {}\n",
    "    for e, i in enumerate(model.beta.cpu().topk(15, dim=1).indices):\n",
    "        word_list = []\n",
    "        for j in i:\n",
    "            word_list.append(vocab_dict_reverse[j.item()])\n",
    "        all_list[e] = word_list\n",
    "        print(\"topic-{}\".format(e), word_list)\n",
    "\n",
    "    topic_words_list = list(all_list.values())\n",
    "    now = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "    results = get_topic_qualities(topic_words_list, palmetto_dir=args.palmetto_dir,\n",
    "                                  reference_corpus=[doc.split() for doc in trainds.preprocess_ctm(trainds.nonempty_text)],\n",
    "                                  filename=f'results/{now}.txt')\n",
    "    train_theta = []\n",
    "    test_theta = []\n",
    "    for batch_idx, batch in tqdm(enumerate(trainloader)):\n",
    "        org_input, _, org_bow, _ = batch\n",
    "        org_input = org_input.cuda(gpu_ids[0])\n",
    "        org_bow = org_bow.cuda(gpu_ids[0])\n",
    "        # pos_input = pos_input.cuda(gpu_ids[0])\n",
    "        # pos_bow = pos_bow.cuda(gpu_ids[0])\n",
    "\n",
    "        batch_size = org_input_ids.size(0)\n",
    "\n",
    "        org_dists, org_topic_logit = model.decode(org_input)\n",
    "        # pos_dists, pos_topic_logit = model.decode(pos_input)\n",
    "\n",
    "        org_topic = F.softmax(org_topic_logit, dim=1)\n",
    "        # pos_topic = F.softmax(pos_topic_logit, dim=1)\n",
    "        \n",
    "        train_theta.append(org_topic.detach().cpu())\n",
    "    \n",
    "    train_theta = np.concatenate(train_theta, axis=0)\n",
    "\n",
    "    for batch_idx, batch in tqdm(enumerate(testloader)): \n",
    "        org_input, org_bow = batch\n",
    "        org_input = org_input.cuda(gpu_ids[0])\n",
    "        org_bow = org_bow.cuda(gpu_ids[0])\n",
    "        # pos_input = pos_input.cuda(gpu_ids[0])\n",
    "        # pos_bow = pos_bow.cuda(gpu_ids[0])\n",
    "\n",
    "        batch_size = org_input_ids.size(0)\n",
    "\n",
    "        org_dists, org_topic_logit = model.decode(org_input)\n",
    "        # pos_dists, pos_topic_logit = model.decode(pos_input)\n",
    "\n",
    "        org_topic = F.softmax(org_topic_logit, dim=1)\n",
    "        # pos_topic = F.softmax(pos_topic_logit, dim=1)\n",
    "        \n",
    "        test_theta.append(org_topic.detach().cpu())\n",
    "    \n",
    "    test_theta = np.concatenate(test_theta, axis=0)\n",
    "    \n",
    "    classification_res = evaluate_classification(train_theta, test_theta, textData.targets, textData.test_targets)\n",
    "    clustering_res = evaluate_clustering(test_theta, textData.test_targets)\n",
    "    \n",
    "    results.update(classification_res)\n",
    "    results.update(clustering_res)\n",
    "    \n",
    "    \n",
    "    if should_measure_hungarian:\n",
    "        topic_dist = torch.empty((0, n_topic))\n",
    "        model.eval()\n",
    "        evalloader = DataLoader(finetuneds, batch_size=bsz, shuffle=False, num_workers=0)\n",
    "        non_empty_text_index = [i for i, text in enumerate(textData.data) if len(text) != 0]\n",
    "        assert len(finetuneds) == len(non_empty_text_index)\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(evalloader):\n",
    "                org_input, _, org_bow, __ = batch\n",
    "                org_input = org_input.cuda(gpu_ids[0])\n",
    "                org_dists, org_topic_logit = model.decode(org_input)\n",
    "                org_topic = F.softmax(org_topic_logit, dim=1)\n",
    "                topic_dist = torch.cat((topic_dist, org_topic.detach().cpu()), 0)\n",
    "        label_accuracy = measure_hungarian_score(\n",
    "                             topic_dist,\n",
    "                             [target for i, target in enumerate(textData.targets)\n",
    "                              if i in non_empty_text_index]\n",
    "                         )\n",
    "        results['label_match'] = label_accuracy\n",
    "\n",
    "    print(results)\n",
    "    print()\n",
    "    results_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   topic_N   CV_wiki   sim_w2v  diversity                   filename  \\\n",
      "0       50  0.372574  0.110596   0.310667  results/240509_235251.txt   \n",
      "1       50  0.371632  0.128656   0.326667  results/240509_235541.txt   \n",
      "2       50  0.375557  0.137268   0.344000  results/240509_235837.txt   \n",
      "3       50  0.388355  0.114225   0.300000  results/240510_000146.txt   \n",
      "4       50  0.374345  0.117887   0.320000  results/240510_000435.txt   \n",
      "\n",
      "        acc  macro-F1    Purity       NMI  label_match  \n",
      "0  0.074482  0.063808  0.498805  0.470720     0.434418  \n",
      "1  0.078598  0.057332  0.510223  0.483898     0.439809  \n",
      "2  0.045805  0.039117  0.513277  0.488140     0.460580  \n",
      "3  0.020579  0.014715  0.510356  0.482638     0.429291  \n",
      "4  0.027748  0.020221  0.516596  0.494972     0.435920  \n",
      "mean\n",
      "topic_N        50.000000\n",
      "CV_wiki         0.376493\n",
      "sim_w2v         0.121726\n",
      "diversity       0.320267\n",
      "acc             0.049442\n",
      "macro-F1        0.039039\n",
      "Purity          0.509851\n",
      "NMI             0.484074\n",
      "label_match     0.440004\n",
      "dtype: float64\n",
      "std\n",
      "topic_N        0.000000\n",
      "CV_wiki        0.006804\n",
      "sim_w2v        0.011005\n",
      "diversity      0.016637\n",
      "acc            0.026429\n",
      "macro-F1       0.021760\n",
      "Purity         0.006701\n",
      "NMI            0.008884\n",
      "label_match    0.012104\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results_list)\n",
    "print(results_df)\n",
    "print('mean')\n",
    "print(results_df.mean())\n",
    "print('std')\n",
    "print(results_df.std())\n",
    "\n",
    "if args.result_file is not None:\n",
    "    result_filename = f'results/{args.result_file}'\n",
    "else:\n",
    "    result_filename = f'results/{now}.tsv'\n",
    "\n",
    "results_df.to_csv(result_filename, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
